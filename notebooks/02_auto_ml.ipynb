{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0a6015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.4.0 (from autogluon)\n",
      "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting autogluon.multimodal==1.4.0 (from autogluon)\n",
      "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.3.2)\n",
      "Requirement already satisfied: scipy<1.17,>=1.5.4 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.7.1)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.3.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10.3)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading boto3-1.40.66-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.core[all]==1.4.0->autogluon) (21.0.0)\n",
      "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
      "Collecting torch<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate<2.0,>=0.34.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fsspec<=2025.3 (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torchvision<0.23.0,>=0.16.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting scikit-image<0.26.0,>=0.19.1 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
      "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting omegaconf<2.4.0,>=2.1.1 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nltk<3.10,>=3.4.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting fastai<2.9,>=2.3.1 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading fastai-2.8.5-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting numpy<2.4.0,>=1.25.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting lightgbm<4.7,>=4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting spacy<3.9 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading spacy-3.8.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading huggingface_hub-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting joblib<1.7,>=1.2 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
      "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading fugue-0.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /home/vscode/.local/lib/python3.12/site-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (7.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/vscode/.local/lib/python3.12/site-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.66 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading botocore-1.40.66-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting plotly (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: six in /home/vscode/.local/lib/python3.12/site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/site-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (25.0.1)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.9,>=1.8.0 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading fastcore-1.8.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting fasttransform>=0.0.2 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading fasttransform-0.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting plum-dispatch (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading plum_dispatch-2.6.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting cloudpickle (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting triad>=1.0.0 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading triad-1.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting adagio>=0.2.6 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting numpy<2.4.0,>=1.25.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in /home/vscode/.local/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.7)\n",
      "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/vscode/.local/lib/python3.12/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.14.1)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.12/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vscode/.local/lib/python3.12/site-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.12/site-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.12/site-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.12/site-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.26.0)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
      "Collecting numba (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.12/site-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.2.1)\n",
      "Collecting regex>=2021.8.3 (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.12/site-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.12/site-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
      "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/vscode/.local/lib/python3.12/site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (6.31.1)\n",
      "Collecting aiosignal (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting frozenlist (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus_client>=0.7.1 in /home/vscode/.local/lib/python3.12/site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.22.1)\n",
      "Collecting smart_open (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading smart_open-7.4.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.12/site-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.12/site-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.12/site-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.12/site-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.7.14)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading tifffile-2025.10.16-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.12/site-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading murmurhash-1.0.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading preshed-3.0.10-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (75.6.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sympy>=1.13.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting frozendict (from einx->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub[torch] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vscode/.local/lib/python3.12/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vscode/.local/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vscode/.local/lib/python3.12/site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.1)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading blis-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vscode/.local/lib/python3.12/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home/vscode/.local/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.3.8)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting wrapt (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading alembic-1.17.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/vscode/.local/lib/python3.12/site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (2.0.0)\n",
      "Collecting beartype>=0.16.2 (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading beartype-0.22.5-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading google_auth-2.42.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
      "  Downloading marisa_trie-1.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.7)\n",
      "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting packaging>=20.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/vscode/.local/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (6.1.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading autogluon-1.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\n",
      "Downloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\n",
      "Downloading autogluon.multimodal-1.4.0-py3-none-any.whl (454 kB)\n",
      "Downloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\n",
      "Downloading autogluon.timeseries-1.4.0-py3-none-any.whl (189 kB)\n",
      "Downloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading boto3-1.40.66-py3-none-any.whl (139 kB)\n",
      "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading fastai-2.8.5-py3-none-any.whl (235 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading fugue-0.9.2-py3-none-any.whl (280 kB)\n",
      "Downloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
      "Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl (68.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.8.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\n",
      "Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading botocore-1.40.66-py3-none-any.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fastcore-1.8.15-py3-none-any.whl (86 kB)\n",
      "Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading fasttransform-0.0.2-py3-none-any.whl (14 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading murmurhash-1.0.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading preshed-3.0.10-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (869 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m869.3/869.3 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Downloading thinc-8.3.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.10.16-py3-none-any.whl (231 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading triad-1.0.0-py3-none-any.whl (59 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading smart_open-7.4.4-py3-none-any.whl (63 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\n",
      "Downloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plum_dispatch-2.6.0-py3-none-any.whl (42 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "Downloading beartype-0.22.5-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading google_auth-2.42.1-py2.py3-none-any.whl (222 kB)\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
      "  Building wheel for nvidia-ml-py3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19208 sha256=a81952db0a8a75bfe4df6ebc6be2568c2c2c83a32807f541fe24d4ddb4788404\n",
      "  Stored in directory: /home/vscode/.cache/pip/wheels/6e/65/79/33dee66cba26e8204801916dfee7481bccfd22905ebb841fe5\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=ea25b5f5a73bdce67afd668b019103894c53201f787fc6d1164278a038fb6962\n",
      "  Stored in directory: /home/vscode/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "  Building wheel for seqeval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=6701d7a5c4e6a04e37bee3b3db1ec0ec26f6eb8bd9ea753661108c8dbe1ff48a\n",
      "  Stored in directory: /home/vscode/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
      "Installing collected packages: py4j, py-spy, opencensus-context, nvidia-ml-py3, nvidia-cusparselt-cu12, mpmath, distlib, cymem, colorful, antlr4-python3-runtime, xxhash, wrapt, werkzeug, wasabi, triton, toolz, tensorboard-data-server, tabulate, sympy, spacy-loggers, spacy-legacy, shellingham, sentencepiece, safetensors, regex, pytesseract, PySocks, pycryptodome, pyasn1, pyarrow, proto-plus, propcache, plotly, pdf2image, orjson, ordered-set, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, murmurhash, multidict, msgpack, mdurl, markdown, marisa-trie, Mako, loguru, llvmlite, lightning-utilities, lazy-loader, joblib, jmespath, hf-xet, grpcio, greenlet, graphviz, googleapis-common-protos, future, fsspec, frozenlist, frozendict, filelock, fastprogress, fastcore, dill, colorlog, colorama, cloudpickle, cloudpathlib, catalogue, beartype, aiohappyeyeballs, absl-py, yarl, virtualenv, tifffile, tensorboardX, tensorboard, srsly, sqlalchemy, smart_open, rsa, pyasn1-modules, preshed, patsy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, model-index, markdown-it-py, language-data, imageio, huggingface_hub, fastdownload, einx, coreforecast, botocore, blis, aiosignal, xgboost, window-ops, utilsforecast, triad, tokenizers, statsmodels, scikit-image, s3transfer, rich, nvidia-cusolver-cu12, lightgbm, langcodes, jsonschema, hyperopt, google-auth, gluonts, gdown, confection, alembic, aiohttp, typer, transformers, torch, thinc, seqeval, ray, plum-dispatch, optuna, opendatalab, nlpaug, google-api-core, catboost, boto3, aiohttp_cors, adagio, weasel, torchvision, torchmetrics, pytorch-metric-learning, openmim, opencensus, mlforecast, fugue, fasttransform, datasets, autogluon.common, accelerate, timm, statsforecast, spacy, pytorch-lightning, evaluate, autogluon.features, autogluon.core, lightning, fastai, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 21.0.0\n",
      "    Uninstalling pyarrow-21.0.0:\n",
      "      Successfully uninstalled pyarrow-21.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.2\n",
      "    Uninstalling numpy-2.3.2:\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.25.0\n",
      "    Uninstalling jsonschema-4.25.0:\n",
      "      Successfully uninstalled jsonschema-4.25.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 PySocks-1.7.1 absl-py-2.3.1 accelerate-1.11.0 adagio-0.2.6 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiohttp_cors-0.8.1 aiosignal-1.4.0 alembic-1.17.1 antlr4-python3-runtime-4.9.3 autogluon-1.4.0 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.multimodal-1.4.0 autogluon.tabular-1.4.0 autogluon.timeseries-1.4.0 beartype-0.22.5 blis-1.3.0 boto3-1.40.66 botocore-1.40.66 catalogue-2.0.10 catboost-1.2.8 cloudpathlib-0.23.0 cloudpickle-3.1.2 colorama-0.4.6 colorful-0.5.8 colorlog-6.10.1 confection-0.1.5 coreforecast-0.0.16 cymem-2.0.11 datasets-4.0.0 dill-0.3.8 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fastai-2.8.5 fastcore-1.8.15 fastdownload-0.0.7 fastprogress-1.0.3 fasttransform-0.0.2 filelock-3.20.0 frozendict-2.4.6 frozenlist-1.8.0 fsspec-2025.3.0 fugue-0.9.2 future-1.0.0 gdown-5.2.0 gluonts-0.16.2 google-api-core-2.28.1 google-auth-2.42.1 googleapis-common-protos-1.71.0 graphviz-0.21 greenlet-3.2.4 grpcio-1.76.0 hf-xet-1.2.0 huggingface_hub-0.36.0 hyperopt-0.2.7 imageio-2.37.2 jmespath-1.0.1 joblib-1.5.2 jsonschema-4.23.0 langcodes-3.5.0 language-data-1.3.0 lazy-loader-0.4 lightgbm-4.6.0 lightning-2.5.5 lightning-utilities-0.15.2 llvmlite-0.45.1 loguru-0.7.3 marisa-trie-1.3.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 mlforecast-0.14.0 model-index-0.1.11 mpmath-1.3.0 msgpack-1.1.2 multidict-6.7.0 multiprocess-0.70.16 murmurhash-1.0.13 nlpaug-1.1.11 nltk-3.9.2 numba-0.62.1 numpy-2.1.3 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 omegaconf-2.3.0 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.5.0 ordered-set-4.1.0 orjson-3.11.4 patsy-1.0.2 pdf2image-1.17.0 plotly-6.4.0 plum-dispatch-2.6.0 preshed-3.0.10 propcache-0.4.1 proto-plus-1.26.1 py-spy-0.4.1 py4j-0.10.9.9 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.5 pytorch-metric-learning-2.8.1 ray-2.44.1 regex-2025.11.3 rich-14.2.0 rsa-4.9.1 s3transfer-0.14.0 safetensors-0.6.2 scikit-image-0.25.2 sentencepiece-0.2.1 seqeval-1.2.2 shellingham-1.5.4 smart_open-7.4.4 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.44 srsly-2.5.1 statsforecast-2.0.1 statsmodels-0.14.5 sympy-1.14.0 tabulate-0.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.4 thinc-8.3.6 tifffile-2025.10.16 timm-1.0.3 tokenizers-0.21.4 toolz-0.12.1 torch-2.7.1 torchmetrics-1.7.4 torchvision-0.22.1 transformers-4.49.0 triad-1.0.0 triton-3.3.1 typer-0.20.0 utilsforecast-0.2.11 virtualenv-20.35.4 wasabi-1.1.3 weasel-0.4.1 werkzeug-3.1.3 window-ops-0.0.15 wrapt-2.0.0 xgboost-3.0.5 xxhash-3.6.0 yarl-1.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b6a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a053b4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_A</th>\n",
       "      <th>feature_B</th>\n",
       "      <th>feature_C</th>\n",
       "      <th>feature_D</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.389851</td>\n",
       "      <td>48.685434</td>\n",
       "      <td>24.514438</td>\n",
       "      <td>1.501245</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.840387</td>\n",
       "      <td>55.927185</td>\n",
       "      <td>24.047195</td>\n",
       "      <td>-1.712662</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.574957</td>\n",
       "      <td>99.102474</td>\n",
       "      <td>24.639858</td>\n",
       "      <td>2.881571</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.560110</td>\n",
       "      <td>81.087068</td>\n",
       "      <td>20.630862</td>\n",
       "      <td>-0.503385</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.372749</td>\n",
       "      <td>51.507307</td>\n",
       "      <td>19.640574</td>\n",
       "      <td>-0.426312</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_A  feature_B  feature_C  feature_D status\n",
       "0  106.389851  48.685434  24.514438   1.501245     KO\n",
       "1   28.840387  55.927185  24.047195  -1.712662     OK\n",
       "2   32.574957  99.102474  24.639858   2.881571     OK\n",
       "3   12.560110  81.087068  20.630862  -0.503385     OK\n",
       "4  130.372749  51.507307  19.640574  -0.426312     KO"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 500\n",
    "data_list = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    is_ko = np.random.rand() > 0.7  \n",
    "\n",
    "    if is_ko:\n",
    "        status = \"KO\"\n",
    "        feature_A = np.random.normal(loc=100, scale=10) \n",
    "        feature_B = np.random.normal(loc=50, scale=2)   \n",
    "        feature_C = np.random.normal(loc=18, scale=5) \n",
    "    else:\n",
    "        status = \"OK\"\n",
    "        feature_A = np.random.normal(loc=20, scale=15) \n",
    "        feature_B = np.random.normal(loc=50, scale=20)\n",
    "        feature_C = np.random.normal(loc=25, scale=5)\n",
    "\n",
    "    feature_D = np.random.normal(loc=0, scale=1)\n",
    "\n",
    "    data_list.append([feature_A, feature_B, feature_C, feature_D, status])\n",
    "\n",
    "columns = ['feature_A', 'feature_B', 'feature_C', 'feature_D', 'status']\n",
    "train_data = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54819292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP Mon May 26 18:08:30 UTC 2025\n",
      "CPU Count:          4\n",
      "Memory Avail:       11.31 GB / 15.62 GB (72.4%)\n",
      "Disk Space Avail:   15.79 GB / 31.33 GB (50.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\"\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 4\n",
      "Label Column:       status\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['KO', 'OK']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = OK, class 0 = KO\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (OK) vs negative (KO) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11555.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['feature_A', 'feature_B', 'feature_C', 'feature_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['feature_A', 'feature_B', 'feature_C', 'feature_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.96s of the 59.96s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/11.1 GB\n",
      "\t0.99\t = Validation score   (accuracy)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 56.07s of the 56.07s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/11.1 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 55.92s of the 55.91s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 55.27s of the 55.27s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 54.77s of the 54.77s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 54.14s of the 54.14s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 53.69s of the 53.69s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 53.23s of the 53.23s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/11.0 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 52.26s of the 52.25s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 52.18s of the 52.17s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/11.0 GB\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.99\t = Validation score   (accuracy)\n",
      "\t2.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 50.01s of the 50.01s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/11.0 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.96s of the 49.79s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9765.1 rows/s (100 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (100 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x76b923cf10a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_column = 'status'\n",
    "\n",
    "predictor = TabularPredictor(label=label_column, path='autogluon_models')\n",
    "\n",
    "predictor.fit(train_data, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392f9119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 4 features using 500 rows with 5 shuffle sets...\n",
      "\t0.38s\t= Expected runtime (0.08s per shuffle set)\n",
      "\t0.15s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "           importance    stddev       p_value  n  p99_high   p99_low\n",
      "feature_A      0.4396  0.012522  7.891743e-08  5  0.465383  0.413817\n",
      "feature_C      0.0024  0.002191  3.524200e-02  5  0.006911 -0.002111\n",
      "feature_D      0.0012  0.001095  3.524200e-02  5  0.003456 -0.001056\n",
      "feature_B      0.0004  0.000894  1.869505e-01  5  0.002242 -0.001442\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor.feature_importance(data=train_data)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e64f9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.210803</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.210803</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.955935</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.955935</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>1.021289</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.403718</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.403718</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.073805</td>\n",
       "      <td>0.043880</td>\n",
       "      <td>0.585268</td>\n",
       "      <td>0.073805</td>\n",
       "      <td>0.043880</td>\n",
       "      <td>0.585268</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.033472</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.033472</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.089617</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>0.412288</td>\n",
       "      <td>0.089617</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>0.412288</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.146943</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.146943</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.99</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>2.153192</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>2.153192</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.00</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.072418</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.072418</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.99</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>3.886053</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>3.886053</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0         LightGBMLarge       1.000       1.00    accuracy        0.000998   \n",
       "1              CatBoost       1.000       1.00    accuracy        0.002412   \n",
       "2       NeuralNetFastAI       1.000       1.00    accuracy        0.012694   \n",
       "3   WeightedEnsemble_L2       1.000       1.00    accuracy        0.013902   \n",
       "4        ExtraTreesGini       1.000       1.00    accuracy        0.072316   \n",
       "5      RandomForestGini       1.000       1.00    accuracy        0.073805   \n",
       "6      RandomForestEntr       1.000       1.00    accuracy        0.075223   \n",
       "7        ExtraTreesEntr       1.000       1.00    accuracy        0.089617   \n",
       "8              LightGBM       0.998       1.00    accuracy        0.000766   \n",
       "9        NeuralNetTorch       0.998       0.99    accuracy        0.005810   \n",
       "10              XGBoost       0.998       1.00    accuracy        0.006057   \n",
       "11           LightGBMXT       0.990       0.99    accuracy        0.002216   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.000360  0.210803                 0.000998                0.000360   \n",
       "1        0.000507  0.627209                 0.002412                0.000507   \n",
       "2        0.009591  0.955935                 0.012694                0.009591   \n",
       "3        0.010241  1.021289                 0.001208                0.000650   \n",
       "4        0.034103  0.403718                 0.072316                0.034103   \n",
       "5        0.043880  0.585268                 0.073805                0.043880   \n",
       "6        0.033472  0.455655                 0.075223                0.033472   \n",
       "7        0.033905  0.412288                 0.089617                0.033905   \n",
       "8        0.000375  0.146943                 0.000766                0.000375   \n",
       "9        0.002770  2.153192                 0.005810                0.002770   \n",
       "10       0.001685  0.072418                 0.006057                0.001685   \n",
       "11       0.000487  3.886053                 0.002216                0.000487   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.210803            1       True         11  \n",
       "1            0.627209            1       True          5  \n",
       "2            0.955935            1       True          8  \n",
       "3            0.065355            2       True         12  \n",
       "4            0.403718            1       True          6  \n",
       "5            0.585268            1       True          3  \n",
       "6            0.455655            1       True          4  \n",
       "7            0.412288            1       True          7  \n",
       "8            0.146943            1       True          2  \n",
       "9            2.153192            1       True         10  \n",
       "10           0.072418            1       True          9  \n",
       "11           3.886053            1       True          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325db198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP Mon May 26 18:08:30 UTC 2025\n",
      "CPU Count:          4\n",
      "Memory Avail:       10.22 GB / 15.62 GB (65.4%)\n",
      "Disk Space Avail:   15.65 GB / 31.33 GB (49.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP Mon May 26 18:08:30 UTC 2025\n",
      "CPU Count:          4\n",
      "Memory Avail:       10.22 GB / 15.62 GB (65.4%)\n",
      "Disk Space Avail:   15.65 GB / 31.33 GB (49.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\"\n",
      "Train Data Rows:    891\n",
      "Train Data Columns: 11\n",
      "Label Column:       Survived\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\"\n",
      "Train Data Rows:    891\n",
      "Train Data Columns: 11\n",
      "Label Column:       Survived\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10469.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10469.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 8\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 8\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t11 features in original data used to generate 28 features in processed data.\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t11 features in original data used to generate 28 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.77s of the 59.77s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.77s of the 59.77s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 59.47s of the 59.47s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 59.47s of the 59.47s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 59.16s of the 59.16s of remaining time.\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 59.16s of the 59.16s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 58.55s of the 58.55s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 58.55s of the 58.55s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 57.93s of the 57.92s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 57.93s of the 57.92s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 57.21s of the 57.21s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 57.21s of the 57.21s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 56.51s of the 56.51s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 56.51s of the 56.51s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8101\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 55.91s of the 55.91s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8101\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 55.91s of the 55.91s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 55.33s of the 55.33s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 55.33s of the 55.33s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 55.05s of the 55.05s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 55.05s of the 55.05s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.8492\t = Validation score   (accuracy)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 52.74s of the 52.74s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8492\t = Validation score   (accuracy)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 52.74s of the 52.74s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.2 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.77s of the 52.14s of remaining time.\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.77s of the 52.14s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 12677.8 rows/s (179 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (179 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "\tEnsemble Weights: {'CatBoost': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 12677.8 rows/s (179 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (179 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\")\n",
      "Computing feature importance via permutation shuffling for 11 features using 891 rows with 5 shuffle sets...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspaces/capping_piston_ai_agent/notebooks/autogluon_models\")\n",
      "Computing feature importance via permutation shuffling for 11 features using 891 rows with 5 shuffle sets...\n",
      "\t3.58s\t= Expected runtime (0.72s per shuffle set)\n",
      "\t3.58s\t= Expected runtime (0.72s per shuffle set)\n",
      "\t1.14s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "\t1.14s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "             importance    stddev   p_value  n  p99_high   p99_low\n",
      "Sex            0.115152  0.006715  0.000001  5  0.128978  0.101325\n",
      "Name           0.081481  0.012130  0.000057  5  0.106456  0.056507\n",
      "Ticket         0.062626  0.006467  0.000013  5  0.075942  0.049311\n",
      "Pclass         0.046914  0.006319  0.000039  5  0.059925  0.033903\n",
      "Age            0.034119  0.005240  0.000065  5  0.044909  0.023329\n",
      "SibSp          0.028507  0.002817  0.000011  5  0.034308  0.022707\n",
      "Parch          0.023120  0.002327  0.000012  5  0.027912  0.018328\n",
      "Cabin          0.022447  0.006096  0.000593  5  0.034998  0.009895\n",
      "Fare           0.014590  0.001775  0.000026  5  0.018244  0.010936\n",
      "Embarked       0.013692  0.001665  0.000026  5  0.017120  0.010265\n",
      "PassengerId    0.013244  0.002680  0.000191  5  0.018761  0.007726\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Step 1: Load the data\n",
    "file_path = \"../data/raw/train.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Train the model\n",
    "label_column = 'Survived'\n",
    "predictor = TabularPredictor(label=label_column, path='autogluon_models')\n",
    "predictor.fit(data, time_limit=60)\n",
    "\n",
    "# Step 3: Get feature importance\n",
    "feature_importance = predictor.feature_importance(data=data)\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d39c6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.057523</td>\n",
       "      <td>0.522995</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.057523</td>\n",
       "      <td>0.522995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>0.055830</td>\n",
       "      <td>0.548988</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>0.055830</td>\n",
       "      <td>0.548988</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.056203</td>\n",
       "      <td>0.519780</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.056203</td>\n",
       "      <td>0.519780</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.928171</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.590089</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.590089</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.307998</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.307998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.903479</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.020092</td>\n",
       "      <td>0.014119</td>\n",
       "      <td>3.056133</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.896745</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>2.295783</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>2.295783</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.879910</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.859708</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.698428</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.698428</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.854097</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.283735</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.283735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0        ExtraTreesGini    0.962963   0.815642    accuracy        0.067530   \n",
       "1      RandomForestGini    0.962963   0.815642    accuracy        0.078247   \n",
       "2      RandomForestEntr    0.962963   0.815642    accuracy        0.080002   \n",
       "3        ExtraTreesEntr    0.961841   0.810056    accuracy        0.071357   \n",
       "4         LightGBMLarge    0.928171   0.815642    accuracy        0.003974   \n",
       "5              LightGBM    0.905724   0.821229    accuracy        0.007267   \n",
       "6   WeightedEnsemble_L2    0.903479   0.871508    accuracy        0.020092   \n",
       "7        NeuralNetTorch    0.896745   0.849162    accuracy        0.013553   \n",
       "8       NeuralNetFastAI    0.892256   0.826816    accuracy        0.019481   \n",
       "9               XGBoost    0.879910   0.815642    accuracy        0.008618   \n",
       "10             CatBoost    0.859708   0.826816    accuracy        0.005259   \n",
       "11           LightGBMXT    0.854097   0.815642    accuracy        0.008503   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.055514  0.619512                 0.067530                0.055514   \n",
       "1        0.057523  0.522995                 0.078247                0.057523   \n",
       "2        0.055830  0.548988                 0.080002                0.055830   \n",
       "3        0.056203  0.519780                 0.071357                0.056203   \n",
       "4        0.002892  0.590089                 0.003974                0.002892   \n",
       "5        0.002871  0.307998                 0.007267                0.002871   \n",
       "6        0.014119  3.056133                 0.001280                0.000669   \n",
       "7        0.009530  2.295783                 0.013553                0.009530   \n",
       "8        0.007278  0.569583                 0.019481                0.007278   \n",
       "9        0.004374  0.262110                 0.008618                0.004374   \n",
       "10       0.003921  0.698428                 0.005259                0.003921   \n",
       "11       0.002906  0.283735                 0.008503                0.002906   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.619512            1       True          6  \n",
       "1            0.522995            1       True          3  \n",
       "2            0.548988            1       True          4  \n",
       "3            0.519780            1       True          7  \n",
       "4            0.590089            1       True         11  \n",
       "5            0.307998            1       True          2  \n",
       "6            0.061923            2       True         12  \n",
       "7            2.295783            1       True         10  \n",
       "8            0.569583            1       True          8  \n",
       "9            0.262110            1       True          9  \n",
       "10           0.698428            1       True          5  \n",
       "11           0.283735            1       True          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c25807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importance to a CSV file\n",
    "feature_importance.to_csv(\"../data/processed/feature_importance.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
