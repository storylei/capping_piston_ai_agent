{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e61214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b1a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic train.csv data loaded successfully!\n",
      "Dataset shape: (891, 12) (rows, columns)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "Descriptive statistics for numerical columns:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Distribution of 'Survived' column:\n",
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "0: Not Survived, 1: Survived\n"
     ]
    }
   ],
   "source": [
    "# Check if the file exists\n",
    "if not os.path.exists(titanic_train_path):\n",
    "    print(f\"Error: train.csv not found at {titanic_train_path}\")\n",
    "    print(\"Please ensure you have downloaded and unzipped titanic.zip,\")\n",
    "    print(\"and placed train.csv into the 'data/raw/' directory of your project.\")\n",
    "else:\n",
    "    # Load the dataset\n",
    "    df_titanic = pd.read_csv(titanic_train_path)\n",
    "    print(\"Titanic train.csv data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df_titanic.shape} (rows, columns)\")\n",
    "\n",
    "    # Display the first few rows of the data\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df_titanic.head())\n",
    "\n",
    "    # Display basic information about the dataset (column names, non-null counts, data types)\n",
    "    print(\"\\nDataset Information:\")\n",
    "    df_titanic.info()\n",
    "\n",
    "    # Display descriptive statistics for numerical columns\n",
    "    print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "    print(df_titanic.describe())\n",
    "\n",
    "    # Check the distribution of the target variable 'Survived'\n",
    "    print(\"\\nDistribution of 'Survived' column:\")\n",
    "    print(df_titanic['Survived'].value_counts())\n",
    "    print(\"0: Not Survived, 1: Survived\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3dac727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical features before preprocessing: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Categorical features before preprocessing: ['Sex', 'Embarked']\n",
      "\n",
      "Training set features shape (original): (712, 7)\n",
      "Test set features shape (original): (179, 7)\n",
      "\n",
      "Data preprocessing complete!\n",
      "Processed training set features shape: (712, 10)\n",
      "Number of processed feature names: 10\n",
      "Example of processed feature names (first 10): ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15239/2897246885.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed['Embarked'].fillna(most_frequent_embarked, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_titanic is the DataFrame loaded in Step 1\n",
    "\n",
    "# Create a copy of the data to avoid modifying the original DataFrame\n",
    "df_processed = df_titanic.copy()\n",
    "\n",
    "# 1. Handle Missing Values\n",
    "\n",
    "# 'Age' column: Impute with median, as age distribution might not be normal, and median is robust to outliers\n",
    "age_imputer = SimpleImputer(strategy='median')\n",
    "df_processed['Age'] = age_imputer.fit_transform(df_processed[['Age']])\n",
    "\n",
    "# 'Embarked' column: Impute with mode, as it is a categorical feature\n",
    "# First, find the mode\n",
    "most_frequent_embarked = df_processed['Embarked'].mode()[0]\n",
    "df_processed['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
    "\n",
    "# 'Cabin' column: Too many missing values, and the feature itself might be too complex for simple models.\n",
    "# Typically dropped or converted to a binary \"has_cabin_info\" feature.\n",
    "# For this task, we choose to drop it directly.\n",
    "df_processed.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# 2. Feature Selection\n",
    "# Remove 'PassengerId', 'Name', 'Ticket' as they are not directly relevant for classification\n",
    "# 'Survived' is the target variable and should also be removed from features\n",
    "features_to_drop = ['PassengerId', 'Name', 'Ticket']\n",
    "df_features = df_processed.drop(columns=features_to_drop + ['Survived'])\n",
    "target = df_processed['Survived']\n",
    "\n",
    "# 3. Identify Numerical and Categorical Features\n",
    "numeric_features = df_features.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = df_features.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical features before preprocessing: {numeric_features}\")\n",
    "print(f\"Categorical features before preprocessing: {categorical_features}\")\n",
    "\n",
    "# 4. Build Preprocessing Pipelines\n",
    "# Numerical feature processing: Standardization\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()) # Standardize numerical features\n",
    "])\n",
    "\n",
    "# Categorical feature processing: One-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Use ColumnTransformer to apply different preprocessing steps to different types of features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 5. Split data into training and testing sets\n",
    "# test_size=0.2 means 20% of the data is used for testing, random_state ensures reproducibility\n",
    "# stratify=target ensures that the proportion of 'Survived' in training and testing sets is similar to the original data, which is important for imbalanced datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "print(f\"\\nTraining set features shape (original): {X_train.shape}\")\n",
    "print(f\"Test set features shape (original): {X_test.shape}\")\n",
    "\n",
    "# Apply the preprocessor to the training data and transform it\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "# Apply the preprocessor to the test data (only transform, do not refit)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get the names of the processed features\n",
    "# For one-hot encoded categorical features, names will be expanded\n",
    "processed_feature_names = numeric_features + \\\n",
    "                          list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    "\n",
    "print(\"\\nData preprocessing complete!\")\n",
    "print(f\"Processed training set features shape: {X_train_processed.shape}\")\n",
    "print(f\"Number of processed feature names: {len(processed_feature_names)}\")\n",
    "print(\"Example of processed feature names (first 10):\", processed_feature_names[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
