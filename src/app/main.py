import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import os

# Add src to Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from data_processing import DataLoader, DataPreprocessor
from analysis import AnalysisEngine

# Initialize app components
st.set_page_config(page_title="Statistical AI Agent", layout="wide")

# Initialize processors
if 'data_loader' not in st.session_state:
    st.session_state.data_loader = DataLoader()
if 'data_preprocessor' not in st.session_state:
    st.session_state.data_preprocessor = DataPreprocessor()
if 'analysis_engine' not in st.session_state:
    st.session_state.analysis_engine = AnalysisEngine()

def load_data_with_loader(filename):
    """Load data using DataLoader"""
    try:
        loader = DataLoader()
        df = loader.load_csv(filename)
        st.success(f"âœ… Successfully loaded: {filename} ({df.shape[0]} rows Ã— {df.shape[1]} cols)")
        return df
    except Exception as e:
        st.error(f"Failed to load data: {str(e)}")
        return pd.DataFrame()

def load_default_data():
    """Load default dataset or let user choose"""
    loader = DataLoader()
    available_datasets = loader.get_available_datasets()
    
    if not available_datasets:
        st.error("No CSV files found in data/raw/ directory")
        return pd.DataFrame()
    
    # Initialize session state for selected file
    if 'selected_file' not in st.session_state:
        st.session_state.selected_file = available_datasets[0]
    if 'current_data' not in st.session_state:
        st.session_state.current_data = pd.DataFrame()
    
    # Let user choose dataset in sidebar
    with st.sidebar:
        st.header("ðŸ“ Data Selection")
        selected_file = st.selectbox(
            "Choose Dataset:", 
            available_datasets,
            help="Select a CSV file from data/raw/ directory",
            key="dataset_selector"
        )
        
        # Load data when file changes or button clicked
        if (selected_file != st.session_state.selected_file) or st.button("ðŸ”„ Load Data", key="load_data_btn"):
            st.session_state.selected_file = selected_file
            st.session_state.current_data = load_data_with_loader(selected_file)
            # Clear preprocessing state when new data is loaded
            for key in ['label_col', 'ok_values', 'ko_values', 'processed_df', 'preprocessing_summary']:
                if key in st.session_state:
                    del st.session_state[key]
    
    # Return current data
    if st.session_state.current_data.empty:
        st.session_state.current_data = load_data_with_loader(st.session_state.selected_file)
    
    return st.session_state.current_data

def display_sidebar(df):
    """Configure all sidebar controls"""
    with st.sidebar:
        st.header("âš™ï¸ Control Panel")
        
        # Dataset information
        if not df.empty:
            st.info(f"ðŸ“Š Current Data: {df.shape[0]} rows Ã— {df.shape[1]} columns")
            
            # Data validation
            is_valid, msg = st.session_state.data_loader.validate_data_for_analysis(df)
            if is_valid:
                st.success(f"âœ… {msg}")
            else:
                st.error(f"âŒ {msg}")
                return
        
        # OK/KO Label Configuration
        with st.expander("ðŸ·ï¸ OK/KO Label Configuration", expanded=True):
            # Suggested label columns
            suggested_cols = st.session_state.data_loader.suggest_label_columns(df)
            if suggested_cols:
                st.info(f"ðŸ’¡ Suggested label columns: {', '.join(suggested_cols)}")
            
            label_col = st.selectbox(
                "Select Label Column:", 
                options=df.columns,
                help="Choose the column containing classification labels"
            )
            
            if label_col:
                unique_vals = df[label_col].dropna().unique().tolist()
                st.write(f"Unique values in '{label_col}': {unique_vals}")
                
                # OK values selection (multi-select support)
                ok_values = st.multiselect(
                    "Select values as 'OK':",
                    options=unique_vals,
                    help="You can select multiple values as OK category"
                )
                
                if ok_values:
                    ko_values = [v for v in unique_vals if v not in ok_values]
                    st.write(f"**OK Category**: {ok_values}")
                    st.write(f"**KO Category**: {ko_values}")
                    
                    if st.button("âœ… Confirm OK/KO Configuration", key="confirm_okko"):
                        st.session_state['label_col'] = label_col
                        st.session_state['ok_values'] = ok_values
                        st.session_state['ko_values'] = ko_values
                        st.success("Configuration saved!")
        
        # Data Preprocessing Configuration
        if 'label_col' in st.session_state:
            with st.expander("ðŸ”§ Data Preprocessing", expanded=False):
                st.subheader("Missing Value Handling")
                
                # Show missing value information
                missing_info = df.isnull().sum()
                cols_with_missing = missing_info[missing_info > 0]
                
                if len(cols_with_missing) > 0:
                    st.write("Columns with missing values:")
                    for col, count in cols_with_missing.items():
                        ratio = count / len(df) * 100
                        st.write(f"- {col}: {count} ({ratio:.1f}%)")
                        
                    # Processing strategy selection
                    use_auto_strategy = st.checkbox("Use automatic handling strategy", value=True)
                    
                    if not use_auto_strategy:
                        st.write("Manual configuration:")
                        # Manual configuration options can be added here
                        st.info("Manual configuration feature under development...")
                else:
                    st.success("âœ… No missing values")
                
                st.subheader("Categorical Variable Encoding")
                categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
                if categorical_cols:
                    encoding_method = st.selectbox(
                        "Encoding method:",
                        options=['label', 'onehot'],
                        help="label: Label encoding, onehot: One-hot encoding"
                    )
                else:
                    st.info("No categorical variables to encode")
                
                st.subheader("Numerical Feature Scaling")
                scale_features = st.checkbox("Scale numerical features", value=False)
                if scale_features:
                    scale_method = st.selectbox(
                        "Scaling method:",
                        options=['standard', 'minmax'],
                        help="standard: Standardization, minmax: Min-max scaling"
                    )
                
                                
                # Important note about data leakage
                st.info("â„¹ï¸ Note: The original label column will be removed after creating OK_KO_Label to prevent data leakage in analysis.")
                
                # Start preprocessing
                if st.button("ðŸš€ Start Preprocessing", key="start_preprocessing"):
                    with st.spinner("Processing data..."):
                        try:
                            # Create OK/KO labels (will automatically drop original label column)
                            processed_df = st.session_state.data_preprocessor.create_ok_ko_labels(
                                df, st.session_state['label_col'], st.session_state['ok_values'],
                                drop_original=True  # Explicitly drop original label to prevent data leakage
                            )
                            
                            # Handle missing values
                            if len(cols_with_missing) > 0:
                                processed_df = st.session_state.data_preprocessor.handle_missing_values(processed_df)
                            
                            # Encode categorical variables
                            if categorical_cols:
                                processed_df = st.session_state.data_preprocessor.encode_categorical_variables(processed_df)
                            
                            # Scale numerical features
                            if scale_features:
                                processed_df = st.session_state.data_preprocessor.scale_numerical_features(
                                    processed_df, method=scale_method
                                )
                            
                            # Save processed data
                            filename = f"processed_{st.session_state['label_col']}_data.csv"
                            saved_path = st.session_state.data_preprocessor.save_processed_data(processed_df, filename)
                            
                            # Save to session state
                            st.session_state['processed_df'] = processed_df
                            st.session_state['preprocessing_summary'] = st.session_state.data_preprocessor.get_preprocessing_summary(df, processed_df)
                            
                            st.success(f"âœ… Data preprocessing completed! Saved to: {saved_path}")
                            st.info(f"â„¹ï¸  Original label column '{st.session_state['label_col']}' has been removed to prevent data leakage.")
                            
                        except Exception as e:
                            st.error(f"Preprocessing failed: {str(e)}")

def display_data_section(df):
    """Upper main area with tab-based data exploration"""
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“Š Raw Data", "ðŸ” Preprocessing Results", "ðŸ“ˆ Data Analysis", "ðŸ”¬ Advanced Analysis"])

    with tab1:
        st.subheader("Raw Data Preview")
        st.dataframe(df, height=300)
        st.caption(f"Showing {len(df)} rows Ã— {len(df.columns)} columns")
        
        # Basic statistics
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Data Types")
            dtype_info = pd.DataFrame({
                'Column': df.columns,
                'Data Type': df.dtypes.astype(str),
                'Non-Null': df.count(),
                'Unique Values': [df[col].nunique() for col in df.columns]
            })
            st.dataframe(dtype_info, height=200)
        
        with col2:
            st.subheader("Missing Values Summary")
            missing_df = pd.DataFrame({
                'Missing Count': df.isnull().sum(),
                'Missing Ratio (%)': (df.isnull().mean() * 100).round(2)
            })
            missing_df = missing_df[missing_df['Missing Count'] > 0]
            if not missing_df.empty:
                st.dataframe(missing_df, height=200)
            else:
                st.success("âœ… No missing values found")

    with tab2:
        if 'processed_df' in st.session_state:
            st.subheader("Preprocessed Data")
            processed_df = st.session_state['processed_df']
            st.dataframe(processed_df, height=300)
            
            # Show preprocessing summary
            if 'preprocessing_summary' in st.session_state:
                summary = st.session_state['preprocessing_summary']
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Original Shape", f"{summary['original_shape'][0]} Ã— {summary['original_shape'][1]}")
                with col2:
                    st.metric("Processed Shape", f"{summary['processed_shape'][0]} Ã— {summary['processed_shape'][1]}")
                with col3:
                    st.metric("Missing Values", f"{summary['missing_values_before']} â†’ {summary['missing_values_after']}")
                
                if summary['new_columns']:
                    st.info(f"New columns added: {', '.join(summary['new_columns'])}")
                if summary['removed_columns']:
                    st.warning(f"Columns removed: {', '.join(summary['removed_columns'])}")
            
            # OK/KO Distribution
            if 'OK_KO_Label' in processed_df.columns:
                st.subheader("OK/KO Distribution")
                distribution = processed_df['OK_KO_Label'].value_counts()
                
                col1, col2 = st.columns(2)
                with col1:
                    fig, ax = plt.subplots(figsize=(4, 4))
                    ax.pie(distribution.values, labels=distribution.index, autopct='%1.1f%%')
                    ax.set_title("OK/KO Distribution")
                    st.pyplot(fig)
                
                with col2:
                    st.bar_chart(distribution)
                    
        else:
            st.info("Please complete data preprocessing first")

    with tab3:
        st.subheader("Data Exploration Analysis")
        if 'processed_df' in st.session_state:
            processed_df = st.session_state['processed_df']
            
            # Select features to analyze
            numerical_cols = processed_df.select_dtypes(include=['int64', 'float64']).columns.tolist()
            selected_features = st.multiselect("Select numerical features to analyze:", numerical_cols)
            
            if selected_features:
                if 'OK_KO_Label' in processed_df.columns:
                    # Analyze by OK/KO groups
                    st.subheader("OK vs KO Feature Comparison")
                    
                    ok_data = processed_df[processed_df['OK_KO_Label'] == 'OK']
                    ko_data = processed_df[processed_df['OK_KO_Label'] == 'KO']
                    
                    for feature in selected_features:
                        st.write(f"**{feature}** Statistical Comparison:")
                        
                        comparison_df = pd.DataFrame({
                            'OK': [
                                ok_data[feature].mean(),
                                ok_data[feature].std(),
                                ok_data[feature].median()
                            ],
                            'KO': [
                                ko_data[feature].mean(),
                                ko_data[feature].std(),
                                ko_data[feature].median()
                            ]
                        }, index=['Mean', 'Std Dev', 'Median'])
                        
                        st.dataframe(comparison_df.round(4))
                        
                        # Distribution plot
                        fig, ax = plt.subplots(figsize=(8, 4))
                        ax.hist(ok_data[feature].dropna(), alpha=0.5, label='OK', bins=20)
                        ax.hist(ko_data[feature].dropna(), alpha=0.5, label='KO', bins=20)
                        ax.set_xlabel(feature)
                        ax.set_ylabel('Frequency')
                        ax.set_title(f'{feature} Distribution Comparison')
                        ax.legend()
                        st.pyplot(fig)
                else:
                    # Basic statistical analysis
                    st.dataframe(processed_df[selected_features].describe())
        else:
            st.info("Please complete data preprocessing first")

    with tab4:
        st.subheader("ðŸ”¬ Advanced Feature Analysis")
        
        if 'processed_df' in st.session_state:
            processed_df = st.session_state['processed_df']
            
            if 'OK_KO_Label' in processed_df.columns:
                st.info("ðŸŽ¯ This module automatically identifies features that best distinguish between OK and KO cases using statistical tests and machine learning algorithms.")
                
                # Analysis configuration
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.subheader("âš™ï¸ Analysis Settings")
                    
                    # Analysis method selection
                    analysis_types = st.multiselect(
                        "Select analysis methods:",
                        options=['Statistical Tests', 'Machine Learning Feature Importance', 'Combined Analysis'],
                        default=['Combined Analysis'],
                        help="Choose which analysis methods to apply"
                    )
                    
                    # Top features to display
                    top_n = st.slider("Top N features to display:", min_value=5, max_value=min(20, len(processed_df.columns)-1), value=10)
                
                with col2:
                    st.subheader("ðŸ“Š Data Summary")
                    ok_count = len(processed_df[processed_df['OK_KO_Label'] == 'OK'])
                    ko_count = len(processed_df[processed_df['OK_KO_Label'] == 'KO'])
                    total_features = len(processed_df.columns) - 1  # Exclude label column
                    
                    st.metric("OK Samples", ok_count)
                    st.metric("KO Samples", ko_count)  
                    st.metric("Total Features", total_features)
                
                # Start Analysis Button
                if st.button("ðŸš€ Run Advanced Analysis", type="primary"):
                    if analysis_types:
                        with st.spinner("Running comprehensive feature analysis... This may take a few moments."):
                            try:
                                # Run analysis
                                analysis_results = st.session_state.analysis_engine.analyze_all(processed_df)
                                st.session_state['analysis_results'] = analysis_results
                                st.success("âœ… Advanced analysis completed!")
                            except Exception as e:
                                st.error(f"Analysis failed: {str(e)}")
                                st.exception(e)
                    else:
                        st.warning("Please select at least one analysis method")
                
                # Display Results
                if 'analysis_results' in st.session_state:
                    results = st.session_state['analysis_results']
                    
                    st.subheader("ðŸ“‹ Analysis Results")
                    
                    # Summary metrics
                    summary = results.get('summary', {})
                    
                    if summary:
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Significant Features", 
                                     summary['analysis_summary'].get('features_with_statistical_significance', 0))
                        with col2:
                            st.metric("ML Models Tested", 
                                     summary['analysis_summary'].get('ml_models_evaluated', 0))
                        with col3:
                            st.metric("Best CV Accuracy", 
                                     f"{summary['analysis_summary'].get('cross_validated_accuracy', 0):.3f}")
                        with col4:
                            st.metric("Consensus Features", 
                                     len(summary.get('consensus_features', [])))
                    
                    # Feature Rankings Tabs
                    rank_tab1, rank_tab2, rank_tab3 = st.tabs(["ðŸ† Combined Ranking", "ðŸ“Š Statistical Analysis", "ðŸ¤– ML Feature Importance"])
                    
                    with rank_tab1:
                        st.subheader("ðŸ† Combined Feature Ranking")
                        st.write("Features ranked by combining statistical significance and ML importance scores")
                        
                        combined_ranking = summary.get('top_ml_features', [])[:top_n]
                        if combined_ranking:
                            ranking_df = pd.DataFrame(combined_ranking)
                            # Handle both 'importance' (from AutoGluon) and 'combined_score' fields
                            score_field = 'importance' if 'importance' in ranking_df.columns else 'combined_score'
                            if score_field in ranking_df.columns:
                                ranking_df[score_field] = ranking_df[score_field].round(4)
                            st.dataframe(ranking_df, height=400)
                            
                            # Visualization
                            if combined_ranking:
                                fig, ax = plt.subplots(figsize=(10, 6))
                                features = [item['feature'] for item in combined_ranking]
                                # Get scores from the appropriate field
                                scores = [item.get('importance', item.get('combined_score', 0)) for item in combined_ranking]
                                
                                bars = ax.barh(features[::-1], scores[::-1])
                                ax.set_xlabel('Feature Importance Score')
                                ax.set_title(f'Top {len(features)} Features by Combined Ranking')
                                
                                # Color bars by score
                                if max(scores) > 0:
                                    for i, bar in enumerate(bars):
                                        bar.set_color(plt.cm.RdYlBu_r(scores[::-1][i] / max(scores)))
                                
                                plt.tight_layout()
                                st.pyplot(fig)
                        else:
                            st.info("No combined ranking available")
                    
                    with rank_tab2:
                        st.subheader("ðŸ“Š Statistical Analysis Results")
                        
                        statistical_results = results.get('statistical_analysis', {})
                        stat_ranking = summary.get('top_statistical_features', [])[:top_n]
                        
                        if stat_ranking:
                            st.write("Features ranked by statistical significance (p-value and effect size)")
                            
                            stat_df = pd.DataFrame(stat_ranking)
                            if 'p_value' in stat_df.columns:
                                stat_df['p_value'] = stat_df['p_value'].round(6)
                            if 'effect_size' in stat_df.columns:
                                stat_df['effect_size'] = stat_df['effect_size'].round(4)
                            st.dataframe(stat_df, height=400)
                            
                            # P-value visualization
                            fig, ax = plt.subplots(figsize=(10, 6))
                            features = [item['feature'] for item in stat_ranking]
                            p_values = [item.get('p_value', 1) for item in stat_ranking]
                            
                            # Use negative log p-values for better visualization
                            import numpy as np
                            neg_log_p = [-np.log10(max(p, 1e-16)) for p in p_values]
                            
                            bars = ax.barh(features[::-1], neg_log_p[::-1])
                            ax.set_xlabel('-log10(p-value)')
                            ax.set_title('Statistical Significance of Features')
                            ax.axvline(-np.log10(0.05), color='red', linestyle='--', alpha=0.7, label='p=0.05 threshold')
                            ax.legend()
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                        else:
                            st.info("No statistical analysis results available")
                    
                    with rank_tab3:
                        st.subheader("ðŸ¤– AutoGluon ML Feature Importance")
                        
                        ml_results = results.get('feature_importance', {})
                        
                        # Display best model info
                        best_model_info = ml_results.get('best_model', {})
                        if best_model_info:
                            st.success(f"ðŸ† Best Model: **{best_model_info.get('name', 'Unknown')}** | Validation Score: **{best_model_info.get('score_val', 0):.4f}**")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Validation Accuracy", f"{best_model_info.get('score_val', 0):.4f}")
                            with col2:
                                if best_model_info.get('fit_time'):
                                    st.metric("Training Time", f"{best_model_info.get('fit_time', 0):.2f}s")
                            with col3:
                                if best_model_info.get('pred_time_val'):
                                    st.metric("Prediction Time", f"{best_model_info.get('pred_time_val', 0):.4f}s")
                        
                        # Model leaderboard
                        leaderboard = ml_results.get('model_leaderboard', [])
                        if leaderboard:
                            st.write("**AutoGluon Model Leaderboard:**")
                            leaderboard_df = pd.DataFrame(leaderboard)
                            
                            # Select relevant columns for display
                            display_cols = ['model', 'score_val', 'pred_time_val', 'fit_time', 'stack_level']
                            available_cols = [col for col in display_cols if col in leaderboard_df.columns]
                            
                            if available_cols:
                                display_df = leaderboard_df[available_cols].copy()
                                # Round numeric columns
                                for col in display_df.select_dtypes(include=[np.number]).columns:
                                    display_df[col] = display_df[col].round(4)
                                st.dataframe(display_df, height=300)
                        
                        # Feature importance
                        feature_importance_info = ml_results.get('feature_importance', {})
                        if feature_importance_info:
                            feature_ranking = feature_importance_info.get('feature_ranking', [])[:top_n]
                            
                            if feature_ranking:
                                st.write(f"**Top {len(feature_ranking)} Most Important Features (AutoGluon):**")
                                
                                importance_df = pd.DataFrame(feature_ranking)
                                if not importance_df.empty:
                                    # Display table
                                    display_df = importance_df[['feature', 'importance', 'rank']].copy()
                                    display_df['importance'] = display_df['importance'].round(4)
                                    st.dataframe(display_df, height=300)
                                    
                                    # Feature importance visualization
                                    fig, ax = plt.subplots(figsize=(10, 6))
                                    features = display_df['feature'].tolist()
                                    importances = display_df['importance'].tolist()
                                    
                                    bars = ax.barh(features[::-1], importances[::-1])
                                    ax.set_xlabel('Feature Importance Score')
                                    ax.set_title('AutoGluon Feature Importance (Permutation-based)')
                                    
                                    # Color gradient
                                    for i, bar in enumerate(bars):
                                        bar.set_color(plt.cm.viridis(importances[::-1][i] / max(importances)))
                                    
                                    plt.tight_layout()
                                    st.pyplot(fig)
                            else:
                                st.info("No feature importance data available")
                        else:
                            st.info("Feature importance analysis not yet completed")
                    
                    # Consensus Features
                    if summary.get('consensus_features'):
                        st.subheader("ðŸŽ¯ Consensus Features")
                        st.write("Features that appear in both statistical and ML top rankings:")
                        
                        consensus_features = summary['consensus_features']
                        for i, feature in enumerate(consensus_features, 1):
                            st.write(f"{i}. **{feature}**")
                        
                        if len(consensus_features) > 0:
                            st.success(f"Found {len(consensus_features)} features with strong consensus across methods!")
                        else:
                            st.info("No strong consensus features found. Consider reviewing analysis parameters.")
            else:
                st.warning("OK/KO labels not found. Please complete preprocessing first.")
        else:
            st.info("Please complete data preprocessing to access advanced analysis features.")

def main():
    st.title("ðŸ¤– Statistical AI Agent - Data Analysis Platform")
    st.markdown("Automated OK/KO data analysis, feature identification and model training")
    
    # Load data
    df = load_default_data()
    
    if not df.empty:
        # Build interface
        display_sidebar(df)
        display_data_section(df) 
    else:
        st.warning("Please place your dataset files in data/raw/ folder")
        st.info("Supported file formats: CSV")

if __name__ == "__main__":
    main()