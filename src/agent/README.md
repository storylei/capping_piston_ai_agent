# Agent Module Documentation

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture Design](#architecture-design)
- [Module Descriptions](#module-descriptions)
  - [agent_core.py - Core Engine](#1-agent_corepy---core-engine)
  - [conversation.py - Conversation Manager](#2-conversationpy---conversation-manager)
  - [llm_interface.py - LLM Interface](#3-llm_interfacepy---llm-interface)
  - [plotting_tools.py - Plotting Tools](#4-plotting_toolspy---plotting-tools)
- [Usage Guide](#usage-guide)
- [API Reference](#api-reference)
- [Design Principles](#design-principles)
- [Example Queries](#example-queries)

---

## Overview

The Agent module is an **AI-powered intelligent agent system for industrial sensor data analysis**, specifically designed to analyze NASA C-MAPSS turbofan engine degradation datasets and similar industrial time-series data.

### Key Features

- âœ… **Zero-Hallucination Design**: All numerical computations are performed by Python tools; LLM never generates numbers
- ğŸ“Š **Rich Visualizations**: Supports time series, FFT spectrum, histograms, box plots, violin plots, KDE, and more
- ğŸ¯ **Smart Intent Recognition**: Rule-based deterministic intent parsing
- ğŸ” **Group Analysis**: Automatically distinguishes between healthy (OK) and degraded (KO) samples
- ğŸ¤– **Local LLM Support**: Uses Ollama for local deployment; data never leaves your machine
- ğŸ“ **Full Traceability**: Every analysis result includes structured data summaries

### Technology Stack

```python
- Python 3.8+
- pandas, numpy - Data processing
- matplotlib, seaborn - Visualization
- Ollama (llama3) - Local LLM
- requests - HTTP communication
```

---

## Architecture Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Streamlit UI Layer                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              StatisticalAgent (agent_core.py)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Intent Parser (Rule-based)                      â”‚   â”‚
â”‚  â”‚  - Keyword matching                              â”‚   â”‚
â”‚  â”‚  - Column name recognition                       â”‚   â”‚
â”‚  â”‚  - Parameter extraction                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Tool Execution Engine                           â”‚   â”‚
â”‚  â”‚  â”œâ”€ Statistical Summary                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ Time Series Plot                             â”‚   â”‚
â”‚  â”‚  â”œâ”€ Frequency Spectrum (FFT)                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ Distribution Comparison                      â”‚   â”‚
â”‚  â”‚  â”œâ”€ Feature Comparison                           â”‚   â”‚
â”‚  â”‚  â””â”€ Feature Importance Ranking                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Response Builder (Deterministic Rendering)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                          â”‚
          â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConversationMgr  â”‚      â”‚   PlottingTools      â”‚
â”‚ (conversation.py)â”‚      â”‚ (plotting_tools.py)  â”‚
â”‚                  â”‚      â”‚                      â”‚
â”‚ - Message historyâ”‚      â”‚ - matplotlib/seaborn â”‚
â”‚ - Context mgmt   â”‚      â”‚ - Deterministic statsâ”‚
â”‚ - System prompt  â”‚      â”‚ - Plots + summaries  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLMInterface       â”‚
â”‚ (llm_interface.py)   â”‚
â”‚                      â”‚
â”‚ - Ollama integration â”‚
â”‚ - Streaming response â”‚
â”‚ - Tool call parsing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Module Descriptions

### 1. agent_core.py - Core Engine

**æ–‡ä»¶è¡Œæ•°**: 618è¡Œ  
**æ ¸å¿ƒç±»**: `StatisticalAgent`

#### è®¾è®¡å“²å­¦

```python
"""
Stable Statistical AI Agent:
1) Parse intent (rule-based, deterministic)
2) Call tools (Python)
3) Produce explanation ONLY from tool outputs (no hallucination)
"""
```

#### ä¸»è¦ç»„ä»¶

```python
class StatisticalAgent:
    def __init__(
        self,
        llm_backend: str = "ollama",
        llm_model: str = None,
        api_key: str = None,
        enable_llm_fallback_chat: bool = True,
        enable_llm_interpretation: bool = False,
    ):
        self.llm                    # LLMæ¥å£
        self.conversation           # å¯¹è¯ç®¡ç†å™¨
        self.plotter                # ç»˜å›¾å·¥å…·
        self.current_data           # å½“å‰æ•°æ®é›† (pd.DataFrame)
        self.data_info              # æ•°æ®å…ƒä¿¡æ¯
        self.analysis_results       # åˆ†æç»“æœç¼“å­˜
        self.tool_functions         # å·¥å…·å‡½æ•°æ³¨å†Œè¡¨
```

#### æ ¸å¿ƒå·¥ä½œæµç¨‹

**1. æ„å›¾è§£æ (`_parse_intent`)**

åŸºäºå…³é”®è¯åŒ¹é…çš„ç¡®å®šæ€§è§£æï¼Œè¯†åˆ«ä»¥ä¸‹æ„å›¾ï¼š

| æ„å›¾ç±»å‹ | è§¦å‘å…³é”®è¯ | è¿”å›å·¥å…· |
|---------|-----------|---------|
| ç‰¹å¾é‡è¦æ€§ | "feature importance", "importance ranking" | `get_feature_importance` |
| FFTé¢‘è°± | "fft", "frequency spectrum", "fourier" | `plot_frequency_spectrum` |
| æ—¶é—´åºåˆ— | "time series", "timeseries" | `plot_time_series` |
| åˆ†å¸ƒå›¾ | "histogram", "boxplot", "violin", "kde" | `plot_distribution` |
| ç»Ÿè®¡åˆ†æ | "mean", "variance", "std", "summary" | `get_statistical_summary` |
| å¤šç‰¹å¾å¯¹æ¯” | "compare" + å¤šä¸ªåˆ—å | `compare_features` |

**2. åˆ—ååŒ¹é… (`_match_columns`)**

```python
def _match_columns(self, message: str) -> List[str]:
    """Word-boundary match to avoid substring false positives."""
    # ç¤ºä¾‹: "show sensor_2" â†’ åŒ¹é… "sensor_2" åˆ—
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ \b ç¡®ä¿å®Œæ•´å•è¯åŒ¹é…
```

**3. åˆ†ç»„è¿‡æ»¤è¯†åˆ«**

è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·æ˜¯å¦æƒ³è¦è¿‡æ»¤ç‰¹å®šç»„ï¼š

```python
# "show time series for OK samples" â†’ filter_group = "OK"
# "histogram for KO" â†’ filter_group = "KO"
```

**4. å·¥å…·æ‰§è¡Œ**

6ä¸ªç¡®å®šæ€§å·¥å…·ï¼Œæ¯ä¸ªéƒ½è¿”å›ï¼š

```python
{
    "success": bool,
    "message": str,          # äººç±»å¯è¯»çš„ç»“æœ
    "data": dict,            # ç»“æ„åŒ–æ•°æ®
    "plot": Figure,          # matplotlibå›¾å½¢ï¼ˆå¦‚æœæœ‰ï¼‰
    "summary": dict,         # ç»˜å›¾çš„æ•°å€¼æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
    "warning": str           # è­¦å‘Šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
}
```

#### 6å¤§æ ¸å¿ƒå·¥å…·

##### Tool 1: `get_statistical_summary`

è®¡ç®—ç»Ÿè®¡æ‘˜è¦ï¼Œæ”¯æŒåˆ†ç»„å’ŒæŒ‡å®šæŒ‡æ ‡ã€‚

**å‚æ•°**:
- `columns`: åˆ—ååˆ—è¡¨ï¼ˆé»˜è®¤æ‰€æœ‰æ•°å€¼åˆ—ï¼‰
- `group_by_ok_ko`: æ˜¯å¦æŒ‰OK/KOåˆ†ç»„ï¼ˆé»˜è®¤Trueï¼‰
- `metrics`: æŒ‡å®šæŒ‡æ ‡åˆ—è¡¨ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰

**æ”¯æŒçš„æŒ‡æ ‡**:
- count, mean, median, mode
- std (æ ‡å‡†å·®), variance (æ–¹å·®)
- min, max

**è¿”å›ç¤ºä¾‹**:
```python
{
    "sensor_2": {
        "OK": {"count": 1500, "mean": 642.5, "std": 3.2, ...},
        "KO": {"count": 800, "mean": 643.1, "std": 5.8, ...}
    }
}
```

##### Tool 2: `plot_time_series`

ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾ï¼Œæ™ºèƒ½æ£€æµ‹æ—¶é—´è½´ã€‚

**æ—¶é—´è½´æ£€æµ‹ä¼˜å…ˆçº§**:
1. DataFrame.attrs['time_column'] (C-MAPSSæ ‡è®°)
2. "time_cycles", "cycle" ç­‰åˆ—å
3. DatetimeIndex
4. datetimeç±»å‹åˆ—
5. å›é€€åˆ°æ ·æœ¬ç´¢å¼•ï¼ˆå¸¦è­¦å‘Šï¼‰

**è¿”å›æ‘˜è¦**:
```python
{
    "plot_type": "time_series",
    "column": "sensor_2",
    "x_axis": "Time Cycles (time_cycles)",
    "group_stats": {
        "OK": {"count": 1500, "mean": 642.5, "std": 3.2, ...},
        "KO": {"count": 800, "mean": 643.1, "std": 5.8, ...}
    }
}
```

##### Tool 3: `plot_frequency_spectrum`

FFTé¢‘è°±åˆ†æï¼Œè¯†åˆ«ä¸»å¯¼é¢‘ç‡ã€‚

**è¿”å›æ‘˜è¦**:
```python
{
    "plot_type": "frequency_spectrum",
    "column": "sensor_7",
    "sampling_rate": 1.0,
    "dominant_frequencies": {
        "OK": [(0.05, 234.5), (0.12, 189.3), ...],  # (é¢‘ç‡Hz, å¹…å€¼)
        "KO": [(0.08, 456.7), (0.15, 301.2), ...]
    },
    "note": "Dominant frequencies are top-5 peaks..."
}
```

##### Tool 4: `plot_distribution`

åˆ†å¸ƒå¯¹æ¯”å›¾ï¼Œæ”¯æŒ4ç§å¯è§†åŒ–ç±»å‹ã€‚

**plot_typeé€‰é¡¹**:
- `histogram`: ç›´æ–¹å›¾ï¼ˆå…±äº«binè¾¹ç•Œï¼‰
- `boxplot`: ç®±çº¿å›¾ï¼ˆæ˜¾ç¤ºå››åˆ†ä½æ•°ï¼‰
- `violin`: å°æç´å›¾ï¼ˆåˆ†å¸ƒå½¢çŠ¶ï¼‰
- `kde`: æ ¸å¯†åº¦ä¼°è®¡ï¼ˆå¹³æ»‘æ›²çº¿ï¼‰

**è¿”å›æ‘˜è¦**ï¼ˆhistogramç¤ºä¾‹ï¼‰:
```python
{
    "plot_type": "distribution_histogram",
    "column": "sensor_11",
    "is_categorical": False,
    "group_stats": {
        "OK": {"count": 1500, "mean": 47.3, ...},
        "KO": {"count": 800, "mean": 47.8, ...}
    },
    "histogram_bins": {
        "OK": {"bin_edges": [40, 42, 44, ...], "bin_counts": [23, 45, ...]},
        "KO": {"bin_edges": [40, 42, 44, ...], "bin_counts": [12, 34, ...]}
    }
}
```

##### Tool 5: `compare_features`

å¤šç‰¹å¾å¹¶æ’å¯¹æ¯”ï¼ˆæœ€å¤š6ä¸ªï¼‰ã€‚

**å¸ƒå±€**: 2åˆ—ç½‘æ ¼ï¼Œè‡ªåŠ¨è®¡ç®—è¡Œæ•°

**è¿”å›æ‘˜è¦**:
```python
{
    "plot_type": "feature_comparison",
    "columns": ["sensor_2", "sensor_7", "sensor_11"],
    "per_feature_group_stats": {
        "sensor_2": {"OK": {...}, "KO": {...}},
        "sensor_7": {"OK": {...}, "KO": {...}},
        ...
    }
}
```

##### Tool 6: `get_feature_importance`

ç‰¹å¾é‡è¦æ€§æ’åï¼Œä»ä¸¤ä¸ªæ¥æºè¯»å–ï¼š

**ä¼˜å…ˆçº§**:
1. å½“å‰ä¼šè¯çš„åˆ†æç»“æœ (`self.analysis_results`)
2. å›é€€åˆ°CSVæ–‡ä»¶ (`data/processed/feature_importance.csv`)

**è¿”å›ç¤ºä¾‹**:
```python
{
    "feature_importance": [
        {"rank": 1, "feature": "sensor_11", "importance": 0.234567},
        {"rank": 2, "feature": "sensor_7", "importance": 0.189432},
        ...
    ]
}
```

#### å“åº”æ„å»º

```python
def _render_response_from_tool(self, tool_result: Dict, intent: Dict) -> str:
    """
    Construct final response ONLY using fields returned by the tool:
    - tool_result['message']  # äººç±»å¯è¯»æ¶ˆæ¯
    - tool_result['summary']  # ç»“æ„åŒ–æ‘˜è¦ï¼ˆç»˜å›¾ï¼‰
    - tool_result['warning']  # è­¦å‘Šä¿¡æ¯
    
    å¯é€‰: LLMè§£é‡Š (if enable_llm_interpretation=True)
    """
```

**LLMè§£é‡ŠåŠŸèƒ½** (å¯é€‰):

å½“ `enable_llm_interpretation=True` æ—¶ï¼Œä¼šè°ƒç”¨LLMå¯¹å·¥å…·ç»“æœè¿›è¡Œä¸“å®¶çº§è§£é‡Šï¼š

```python
# ç¤ºä¾‹LLMè§£é‡Šæç¤ºè¯
"""
You are an expert data analyst interpreting results from an industrial 
sensor analysis tool.

The data is from NASA C-MAPSS turbofan engine degradation dataset:
- OK = healthy engine (RUL > threshold)
- KO = degraded engine (RUL <= threshold, approaching failure)

Here are the EXACT results from the analysis tool:
{tool_results}

Provide a brief (2-3 sentences) expert interpretation:
1. What do these numbers mean in the context of engine health?
2. Is there a significant difference between OK and KO groups?
3. What actionable insight can be drawn?

IMPORTANT: Only explain the numbers shown above. Do NOT invent new statistics.
"""
```

---

### 2. conversation.py - å¯¹è¯ç®¡ç†å™¨

**æ–‡ä»¶è¡Œæ•°**: ~120è¡Œ  
**æ ¸å¿ƒç±»**: `ConversationManager`

#### åŠŸèƒ½æ¦‚è¿°

ç®¡ç†å¯¹è¯å†å²ã€ç³»ç»Ÿæç¤ºè¯å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

```python
class ConversationManager:
    def __init__(self, max_history: int = 20):
        self.max_history = 20              # æœ€å¤§ä¿ç•™æ¶ˆæ¯æ•°
        self.messages: List[Dict] = []     # æ¶ˆæ¯åˆ—è¡¨
        self.system_prompt: str = ...      # ç³»ç»Ÿæç¤ºè¯
```

#### æ ¸å¿ƒæ–¹æ³•

**1. æ·»åŠ æ¶ˆæ¯**

```python
def add_message(self, role: str, content: str, metadata: Dict = None):
    """
    Args:
        role: 'user', 'assistant', or 'system'
        content: æ¶ˆæ¯å†…å®¹
        metadata: é™„åŠ å…ƒæ•°æ®ï¼ˆå·¥å…·è°ƒç”¨ã€æ—¶é—´æˆ³ç­‰ï¼‰
    """
    message = {
        'role': role,
        'content': content,
        'timestamp': datetime.now().isoformat()
    }
    if metadata:
        message['metadata'] = metadata
    
    self.messages.append(message)
    # è‡ªåŠ¨è£å‰ªå†å²ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯+æœ€è¿‘20æ¡ï¼‰
```

**2. è·å–LLMæ ¼å¼æ¶ˆæ¯**

```python
def get_messages_for_llm(self, include_system: bool = True) -> List[Dict]:
    """
    è¿”å›æ ¼å¼:
    [
        {'role': 'system', 'content': '...'},
        {'role': 'user', 'content': '...'},
        {'role': 'assistant', 'content': '...'},
        ...
    ]
    """
```

**3. æ·»åŠ ä¸Šä¸‹æ–‡**

```python
def add_context(self, context: str):
    """è¿½åŠ åˆ°ç³»ç»Ÿæç¤ºè¯"""
    self.system_prompt += f"\n\nCurrent Context:\n{context}"
```

#### ç³»ç»Ÿæç¤ºè¯è®¾è®¡

ä¸“é—¨é’ˆå¯¹å·¥ä¸šä¼ æ„Ÿå™¨æ•°æ®åˆ†æï¼š

```python
system_prompt = """
You are a Statistical Analysis AI Agent specialized in analyzing 
industrial sensor datasets with OK/KO labels (e.g., NASA C-MAPSS 
turbofan engine degradation data).

Your capabilities include:
1. Statistical Analysis: mean, median, mode, std, variance
2. Feature Importance: identify discriminative sensors
3. Data Visualization:
   - Histograms, Box plots, Violin plots, KDE plots
   - Time series plots
   - FFT/Frequency spectrum plots
4. Multi-feature Comparison
5. Group Filtering (OK/KO)

Example queries:
- 'Show mean and std for sensor_2'
- 'Plot histogram of sensor_11'
- 'Show time series for KO samples of sensor_7'
- 'Plot FFT for sensor_4'
- 'Get feature importance ranking'
"""
```

---

### 3. llm_interface.py - LLMæ¥å£

**æ–‡ä»¶è¡Œæ•°**: 218è¡Œ  
**æ ¸å¿ƒç±»**: `LLMInterface`

#### åŠŸèƒ½æ¦‚è¿°

æä¾›æœ¬åœ°LLMé›†æˆï¼ˆOllamaï¼‰ï¼Œæ”¯æŒæµå¼å’Œéæµå¼ç”Ÿæˆã€‚

```python
class LLMInterface:
    def __init__(
        self, 
        backend: str = "ollama",  # å§‹ç»ˆä½¿ç”¨Ollama
        model: str = None,         # é»˜è®¤ "llama3:latest"
        api_key: str = None        # å¿½ç•¥ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
    ):
        self.model = model or "llama3:latest"
        self.base_url = "http://localhost:11434"
```

#### æ ¸å¿ƒæ–¹æ³•

**1. æœåŠ¡æ£€æµ‹**

```python
def _check_ollama_available(self):
    """
    æ£€æŸ¥æ­¥éª¤:
    1. å°è¯•è¿æ¥ localhost:11434/api/tags
    2. éªŒè¯æ¨¡å‹æ˜¯å¦å·²å®‰è£…
    3. æä¾›å‹å¥½çš„é”™è¯¯æç¤º
    """
    # å¤±è´¥æ—¶è¾“å‡º:
    # âš ï¸  Warning: Ollama service not running.
    #    Please start Ollama service.
    #    Install: https://ollama.ai/download
```

**2. ç”Ÿæˆå“åº”**

```python
def generate(
    self, 
    messages: List[Dict[str, str]], 
    temperature: float = 0.7,
    max_tokens: int = 2000,
    tools: List[Dict] = None
) -> Dict[str, Any]:
    """
    è¿”å›:
    {
        'content': str,           # ç”Ÿæˆçš„æ–‡æœ¬
        'tool_calls': List,       # å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        'model': str,             # æ¨¡å‹åç§°
        'backend': 'ollama'
    }
    """
```

**3. æ¶ˆæ¯æ ¼å¼è½¬æ¢**

```python
def _messages_to_prompt(
    self, 
    messages: List[Dict[str, str]], 
    tools: List[Dict] = None
) -> str:
    """
    è½¬æ¢ OpenAI é£æ ¼æ¶ˆæ¯ä¸º Ollama prompt:
    
    System: {system_content}
    
    Available Tools:
    - tool_name: description
    
    User: {user_message}
    Assistant: {assistant_message}
    ...
    
    Assistant:
    """
```

**4. å·¥å…·è°ƒç”¨è§£æ**

```python
def _parse_tool_calls(self, content: str) -> Optional[List[Dict]]:
    """
    è§£ææ ¼å¼:
    TOOL_CALL: {"name": "tool_name", "arguments": {...}}
    
    è¿”å›:
    [{
        'type': 'function',
        'function': {
            'name': 'tool_name',
            'arguments': '{"arg1": "value1"}'
        }
    }]
    """
```

**5. æµå¼ç”Ÿæˆ**

```python
def stream_generate(
    self, 
    messages: List[Dict[str, str]], 
    temperature: float = 0.7
):
    """
    Yields: æ–‡æœ¬å—ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰
    
    ä½¿ç”¨ç¤ºä¾‹:
    for chunk in llm.stream_generate(messages):
        print(chunk, end='', flush=True)
    """
```

#### é”™è¯¯å¤„ç†

```python
# è¿æ¥é”™è¯¯
{
    'content': "âŒ Error: Cannot connect to Ollama...",
    'tool_calls': None,
    'error': 'connection_failed'
}

# å…¶ä»–é”™è¯¯
{
    'content': f"âŒ Error: {str(e)}",
    'tool_calls': None,
    'error': str(e)
}
```

---

### 4. plotting_tools.py - ç»˜å›¾å·¥å…·

**æ–‡ä»¶è¡Œæ•°**: 628è¡Œ  
**æ ¸å¿ƒç±»**: `PlottingTools`

#### è®¾è®¡åŸåˆ™

```python
"""
Key design:
- Plot functions MUST return:
  1) 'figure': matplotlib Figure
  2) 'summary': structured facts for deterministic interpretation
- Agent should NOT ask LLM to infer numbers from a figure.
"""
```

#### æ ¸å¿ƒé…ç½®

```python
class PlottingTools:
    def __init__(self):
        sns.set_style("whitegrid")           # seabornæ ·å¼
        plt.rcParams["figure.figsize"] = (10, 6)  # é»˜è®¤å°ºå¯¸
        plt.rcParams["font.size"] = 10       # å­—ä½“å¤§å°
```

#### è¾…åŠ©æ–¹æ³•

**1. æ™ºèƒ½æ—¶é—´è½´æ£€æµ‹**

```python
def _find_time_axis(self, df: pd.DataFrame) -> Tuple[Optional[pd.Series], Optional[str]]:
    """
    æ£€æµ‹ä¼˜å…ˆçº§:
    1. df.attrs['time_column']  # C-MAPSSä¸“ç”¨æ ‡è®°
    2. åˆ—ååŒ¹é…: time_cycles, cycle, cycles
    3. DatetimeIndex
    4. datetimeç±»å‹åˆ—
    5. åˆ—åæç¤º: timestamp, time, date
    
    è¿”å›: (æ—¶é—´åºåˆ—, è½´æ ‡ç­¾) æˆ– (None, None)
    """
```

**2. æ•°å€¼ç»Ÿè®¡**

```python
def _numeric_stats(self, s: pd.Series) -> Dict[str, Any]:
    """
    è®¡ç®—11é¡¹ç»Ÿè®¡æŒ‡æ ‡:
    - count, mean, std, variance
    - min, max
    - q05, q25, q50 (median), q75, q95
    
    è¿”å›: {"count": 1500, "mean": 642.5, ...}
    """
```

**3. åˆ†ç±»æ£€æµ‹**

```python
def _is_categorical(self, s: pd.Series) -> bool:
    """
    åˆ¤æ–­é€»è¾‘:
    - object/category ç±»å‹ â†’ True
    - æ•°å€¼ç±»å‹ â†’ False (ä¼ æ„Ÿå™¨æ•°æ®ä¸åº”è§†ä¸ºåˆ†ç±»)
    """
```

#### ç»˜å›¾æ–¹æ³•è¯¦è§£

**1. æ—¶é—´åºåˆ—å›¾**

```python
def plot_time_series(
    self,
    df: pd.DataFrame,
    column: str,
    group_by: str = "OK_KO_Label",
    title: str = None,
    separate_groups: bool = True,
    allow_sample_index_fallback: bool = True,
) -> Dict[str, Any]:
    """
    ç‰¹æ€§:
    - æ™ºèƒ½æ—¶é—´è½´æ£€æµ‹
    - è‡ªåŠ¨åˆ†ç»„ç€è‰²
    - å›é€€åˆ°æ ·æœ¬ç´¢å¼•ï¼ˆå¸¦è­¦å‘Šï¼‰
    
    è¿”å›:
    {
        "success": True,
        "figure": <matplotlib.figure.Figure>,
        "plot_type": "time_series",
        "column": "sensor_2",
        "summary": {
            "plot_type": "time_series",
            "column": "sensor_2",
            "x_axis": "Time Cycles (time_cycles)",
            "group_stats": {
                "OK": {"count": 1500, "mean": 642.5, ...},
                "KO": {"count": 800, "mean": 643.1, ...}
            }
        },
        "warning": "No real time axis detected..." (å¦‚æœæœ‰)
    }
    """
```

**2. é¢‘è°±åˆ†æï¼ˆFFTï¼‰**

```python
def plot_frequency_spectrum(
    self,
    df: pd.DataFrame,
    column: str,
    group_by: str = "OK_KO_Label",
    sampling_rate: float = 1.0,
    title: str = None,
    top_k_peaks: int = 5,
) -> Dict[str, Any]:
    """
    FFTæ­¥éª¤:
    1. æ•°æ®æ¸…æ´—ï¼ˆç§»é™¤NaNï¼‰
    2. np.fft.fft() è®¡ç®—
    3. æå–æ­£é¢‘ç‡éƒ¨åˆ†
    4. å³°å€¼æ£€æµ‹ï¼ˆTop-Kï¼‰
    
    è¿”å›:
    {
        "success": True,
        "figure": <Figure>,
        "summary": {
            "plot_type": "frequency_spectrum",
            "column": "sensor_7",
            "sampling_rate": 1.0,
            "dominant_frequencies": {
                "OK": [(0.05, 234.5), (0.12, 189.3), ...],
                "KO": [(0.08, 456.7), (0.15, 301.2), ...]
            },
            "note": "Dominant frequencies are top-5 peaks..."
        }
    }
    """
```

**3. åˆ†å¸ƒå¯¹æ¯”**

```python
def plot_distribution_comparison(
    self,
    df: pd.DataFrame,
    column: str,
    group_by: str = "OK_KO_Label",
    plot_type: str = "histogram",  # histogram|kde|boxplot|violin
    title: str = None,
    bins: int = 30,
) -> Dict[str, Any]:
    """
    4ç§å¯è§†åŒ–æ¨¡å¼:
    
    A. Histogram:
       - å…±äº«binè¾¹ç•Œï¼ˆç¡®ä¿å¯æ¯”æ€§ï¼‰
       - è¿”å›bin_edgeså’Œbin_counts
    
    B. KDE (Kernel Density Estimation):
       - å¹³æ»‘å¯†åº¦æ›²çº¿
       - è¿”å›ç»Ÿè®¡æ‘˜è¦ï¼ˆéKDEå³°å€¼ï¼‰
    
    C. Boxplot:
       - æ˜¾ç¤ºä¸­ä½æ•°ã€å››åˆ†ä½æ•°ã€å¼‚å¸¸å€¼
       - è¿”å›q05, q25, q50, q75, q95
    
    D. Violin:
       - ç»“åˆboxplotå’ŒKDE
       - æ˜¾ç¤ºåˆ†å¸ƒå½¢çŠ¶
    
    è¿”å› (histogramç¤ºä¾‹):
    {
        "success": True,
        "figure": <Figure>,
        "summary": {
            "plot_type": "distribution_histogram",
            "column": "sensor_11",
            "is_categorical": False,
            "group_stats": {
                "OK": {"count": 1500, "mean": 47.3, ...},
                "KO": {"count": 800, "mean": 47.8, ...}
            },
            "histogram_bins": {
                "OK": {
                    "bin_edges": [40.0, 42.0, 44.0, ...],
                    "bin_counts": [23, 45, 67, ...]
                },
                "KO": {...}
            },
            "note": "Histogram uses shared bin edges (bins=30)..."
        }
    }
    """
```

**4. ç‰¹å¾å¯¹æ¯”**

```python
def plot_feature_comparison(
    self,
    df: pd.DataFrame,
    columns: List[str],
    group_by: str = "OK_KO_Label",
    title: str = None,
    bins: int = 20,
) -> Dict[str, Any]:
    """
    å¸ƒå±€:
    - 2åˆ—ç½‘æ ¼
    - è¡Œæ•° = ceil(len(columns) / 2)
    - æ¯ä¸ªå­å›¾ç‹¬ç«‹ç›´æ–¹å›¾
    
    è¿”å›:
    {
        "success": True,
        "figure": <Figure>,
        "summary": {
            "plot_type": "feature_comparison",
            "columns": ["sensor_2", "sensor_7", "sensor_11"],
            "per_feature_group_stats": {
                "sensor_2": {
                    "OK": {"count": 1500, ...},
                    "KO": {"count": 800, ...}
                },
                ...
            },
            "note": "Each subplot is a histogram (bins=20)..."
        }
    }
    """
```

**5. ç›¸å…³æ€§çƒ­å›¾**

```python
def plot_correlation_heatmap(
    self,
    df: pd.DataFrame,
    columns: List[str] = None,
    title: str = None,
    annot: bool = True,
) -> Dict[str, Any]:
    """
    æ­¥éª¤:
    1. é€‰æ‹©æ•°å€¼åˆ—
    2. è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ (df.corr())
    3. seabornçƒ­å›¾å¯è§†åŒ–
    
    è¿”å›:
    {
        "success": True,
        "figure": <Figure>,
        "summary": {
            "plot_type": "correlation_heatmap",
            "columns": ["sensor_2", "sensor_7", ...],
            "correlation_matrix": {
                "sensor_2": {"sensor_2": 1.0, "sensor_7": 0.34, ...},
                "sensor_7": {"sensor_2": 0.34, "sensor_7": 1.0, ...},
                ...
            },
            "note": "Full correlation matrix (rounded to 4 decimals)."
        }
    }
    """
```

**6. å›¾åƒè½¬Base64**

```python
def fig_to_base64(self, fig) -> str:
    """
    ç”¨äºWebæ˜¾ç¤º:
    1. ä¿å­˜åˆ°BytesIOç¼“å†²åŒº
    2. Base64ç¼–ç 
    3. å…³é—­å›¾å½¢é‡Šæ”¾å†…å­˜
    
    è¿”å›: "iVBORw0KGgoAAAANSUhEUgAA..."
    """
```

---

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬åˆå§‹åŒ–

```python
from src.agent.agent_core import StatisticalAgent
import pandas as pd

# 1. åˆ›å»ºAgentå®ä¾‹
agent = StatisticalAgent(
    llm_backend="ollama",
    llm_model="llama3:latest",
    enable_llm_fallback_chat=True,      # å¯ç”¨LLMå¯¹è¯å›é€€
    enable_llm_interpretation=False     # ç¦ç”¨LLMç»“æœè§£é‡Š
)

# 2. åŠ è½½æ•°æ®
df = pd.read_csv("data/processed/processed_data.csv")

# 3. è®¾ç½®æ•°æ®ä¸Šä¸‹æ–‡
agent.set_data_context(df, data_info={
    "source": "NASA C-MAPSS FD001",
    "ok_count": 1500,
    "ko_count": 800
})

# 4. ï¼ˆå¯é€‰ï¼‰è®¾ç½®åˆ†æç»“æœ
agent.set_analysis_results(results_dict)
```

### äº¤äº’å¼æŸ¥è¯¢

```python
# åŸºæœ¬æŸ¥è¯¢
response = agent.chat("show mean and std for sensor_2")

print(response['response'])    # æ ¼å¼åŒ–çš„æ–‡æœ¬å“åº”
print(response['plots'])       # matplotlib Figureåˆ—è¡¨
print(response['tool_results']) # å·¥å…·æ‰§è¡Œç»“æœ
```

### é«˜çº§é€‰é¡¹

```python
# 1. å¯ç”¨LLMä¸“å®¶è§£é‡Š
agent = StatisticalAgent(
    enable_llm_interpretation=True  # LLMä¼šå¯¹ç»“æœæä¾›ä¸“å®¶çº§è§£é‡Š
)

# 2. æµå¼å“åº”ï¼ˆæš‚ä¸æ”¯æŒï¼Œä¿ç•™æ¥å£ï¼‰
response = agent.chat("analyze sensor_7", stream=True)

# 3. è®¿é—®å¯¹è¯å†å²
history = agent.conversation.get_full_history()
for msg in history:
    print(f"{msg['role']}: {msg['content']}")
```

---

## APIå‚è€ƒ

### StatisticalAgent

#### æ„é€ å‡½æ•°

```python
StatisticalAgent(
    llm_backend: str = "ollama",
    llm_model: str = None,
    api_key: str = None,
    enable_llm_fallback_chat: bool = True,
    enable_llm_interpretation: bool = False,
)
```

**å‚æ•°**:
- `llm_backend`: LLMåç«¯ï¼ˆå§‹ç»ˆä¸º"ollama"ï¼‰
- `llm_model`: æ¨¡å‹åç§°ï¼ˆé»˜è®¤"llama3:latest"ï¼‰
- `api_key`: APIå¯†é’¥ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œå®é™…æœªä½¿ç”¨ï¼‰
- `enable_llm_fallback_chat`: å¯ç”¨LLMå¯¹è¯å›é€€ï¼ˆæœªè¯†åˆ«æ„å›¾æ—¶ï¼‰
- `enable_llm_interpretation`: å¯ç”¨LLMç»“æœè§£é‡Šï¼ˆå®éªŒæ€§ï¼‰

#### ä¸»è¦æ–¹æ³•

##### `set_data_context(df, data_info=None)`

è®¾ç½®å½“å‰æ•°æ®é›†å’Œå…ƒä¿¡æ¯ã€‚

**å‚æ•°**:
- `df` (pd.DataFrame): æ•°æ®é›†
- `data_info` (dict, å¯é€‰): å…ƒä¿¡æ¯å­—å…¸

**ç¤ºä¾‹**:
```python
agent.set_data_context(df, {
    "source": "FD001",
    "ok_count": 1500,
    "ko_count": 800
})
```

##### `set_analysis_results(results)`

è®¾ç½®åˆ†æç»“æœï¼ˆç”¨äºç‰¹å¾é‡è¦æ€§ç­‰ï¼‰ã€‚

**å‚æ•°**:
- `results` (dict): åˆ†æç»“æœå­—å…¸

**ç¤ºä¾‹**:
```python
agent.set_analysis_results({
    'feature_importance': {
        'feature_importance': {
            'feature_ranking': [
                {'rank': 1, 'feature': 'sensor_11', 'importance': 0.234},
                ...
            ]
        }
    }
})
```

##### `chat(user_message, stream=False)`

ä¸»è¦èŠå¤©æ¥å£ã€‚

**å‚æ•°**:
- `user_message` (str): ç”¨æˆ·æ¶ˆæ¯
- `stream` (bool): æ˜¯å¦æµå¼å“åº”ï¼ˆä¿ç•™å‚æ•°ï¼Œæš‚æœªå®ç°ï¼‰

**è¿”å›**:
```python
{
    "response": str,              # æ ¼å¼åŒ–çš„æ–‡æœ¬å“åº”
    "plots": List[Figure],        # matplotlibå›¾å½¢åˆ—è¡¨
    "tool_calls": Optional[List], # å·¥å…·è°ƒç”¨ä¿¡æ¯
    "tool_results": List[Dict],   # å·¥å…·æ‰§è¡Œç»“æœ
}
```

---

### ConversationManager

#### æ„é€ å‡½æ•°

```python
ConversationManager(max_history: int = 20)
```

#### ä¸»è¦æ–¹æ³•

##### `add_message(role, content, metadata=None)`

æ·»åŠ æ¶ˆæ¯åˆ°å†å²ã€‚

**å‚æ•°**:
- `role` (str): 'user', 'assistant', æˆ– 'system'
- `content` (str): æ¶ˆæ¯å†…å®¹
- `metadata` (dict, å¯é€‰): é™„åŠ å…ƒæ•°æ®

##### `get_messages_for_llm(include_system=True)`

è·å–LLMæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨ã€‚

**è¿”å›**: `List[Dict[str, str]]`

##### `add_context(context)`

æ·»åŠ ä¸Šä¸‹æ–‡åˆ°ç³»ç»Ÿæç¤ºè¯ã€‚

**å‚æ•°**:
- `context` (str): ä¸Šä¸‹æ–‡ä¿¡æ¯

##### `clear_history()`

æ¸…ç©ºå¯¹è¯å†å²ã€‚

---

### LLMInterface

#### æ„é€ å‡½æ•°

```python
LLMInterface(
    backend: str = "ollama",
    model: str = None,
    api_key: str = None
)
```

#### ä¸»è¦æ–¹æ³•

##### `generate(messages, temperature=0.7, max_tokens=2000, tools=None)`

ç”Ÿæˆå“åº”ã€‚

**å‚æ•°**:
- `messages` (List[Dict]): æ¶ˆæ¯åˆ—è¡¨
- `temperature` (float): é‡‡æ ·æ¸©åº¦ (0.0-2.0)
- `max_tokens` (int): æœ€å¤§tokenæ•°
- `tools` (List[Dict], å¯é€‰): å¯ç”¨å·¥å…·åˆ—è¡¨

**è¿”å›**:
```python
{
    'content': str,
    'tool_calls': Optional[List],
    'model': str,
    'backend': str
}
```

##### `stream_generate(messages, temperature=0.7)`

æµå¼ç”Ÿæˆï¼ˆç”Ÿæˆå™¨ï¼‰ã€‚

**Yields**: `str` (æ–‡æœ¬å—)

---

### PlottingTools

#### æ„é€ å‡½æ•°

```python
PlottingTools()
```

#### ä¸»è¦æ–¹æ³•

æ‰€æœ‰ç»˜å›¾æ–¹æ³•è¿”å›ç»Ÿä¸€æ ¼å¼ï¼š

```python
{
    "success": bool,
    "figure": Optional[matplotlib.figure.Figure],
    "plot_type": str,
    "column": str,
    "summary": Dict[str, Any],
    "error": str (ä»…å¤±è´¥æ—¶),
    "warning": str (å¯é€‰)
}
```

##### `plot_time_series(df, column, group_by="OK_KO_Label", ...)`

æ—¶é—´åºåˆ—å›¾ã€‚

##### `plot_frequency_spectrum(df, column, sampling_rate=1.0, ...)`

FFTé¢‘è°±å›¾ã€‚

##### `plot_distribution_comparison(df, column, plot_type="histogram", ...)`

åˆ†å¸ƒå¯¹æ¯”å›¾ã€‚

##### `plot_feature_comparison(df, columns, ...)`

å¤šç‰¹å¾å¯¹æ¯”ã€‚

##### `plot_correlation_heatmap(df, columns=None, ...)`

ç›¸å…³æ€§çƒ­å›¾ã€‚

##### `fig_to_base64(fig)`

å›¾å½¢è½¬Base64ç¼–ç ã€‚

---

## è®¾è®¡åŸåˆ™

### 1. é›¶å¹»è§‰ä¿è¯

**é—®é¢˜**: LLMå®¹æ˜“"ç¼–é€ "æ•°å­—å’Œç»Ÿè®¡ç»“æœã€‚

**è§£å†³æ–¹æ¡ˆ**:
- âœ… æ‰€æœ‰æ•°å€¼è®¡ç®—ç”±Pythonå·¥å…·å®Œæˆ
- âœ… LLMä»…ç”¨äºå¯¹è¯ç†è§£å’Œè‡ªç„¶è¯­è¨€è§£é‡Š
- âœ… å·¥å…·ç»“æœåŒ…å«å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®
- âœ… å“åº”æ„å»ºä¸¥æ ¼åŸºäºå·¥å…·è¾“å‡º

**ä»£ç ä½“ç°**:
```python
# agent_core.py
def _render_response_from_tool(self, tool_result, intent):
    """
    Construct final response ONLY using fields returned by the tool.
    NEVER ask LLM to infer or compute numbers.
    """
```

### 2. ç¡®å®šæ€§å·¥å…·è®¾è®¡

**åŸåˆ™**: ç›¸åŒè¾“å…¥ â†’ ç›¸åŒè¾“å‡ºï¼ˆå¯é‡ç°ï¼‰

**å®ç°**:
- åŸºäºè§„åˆ™çš„æ„å›¾è§£æï¼ˆéMLï¼‰
- NumPy/Pandasç¡®å®šæ€§è®¡ç®—
- å›ºå®šéšæœºç§å­ï¼ˆå¦‚éœ€è¦ï¼‰
- è¿”å›å®Œæ•´æ•°å€¼æ‘˜è¦

### 3. ç»“æ„åŒ–è¾“å‡º

**æ¯ä¸ªå·¥å…·è¿”å›**:
```python
{
    "success": bool,           # æ‰§è¡ŒçŠ¶æ€
    "message": str,            # äººç±»å¯è¯»ç»“æœ
    "data": dict,              # æœºå™¨å¯è¯»æ•°æ®
    "plot": Figure,            # å›¾å½¢ï¼ˆå¦‚æœæœ‰ï¼‰
    "summary": dict,           # å›¾è¡¨æ•°å€¼æ‘˜è¦
    "error/warning": str       # é”™è¯¯/è­¦å‘Š
}
```

**å¥½å¤„**:
- å¯è¿½æº¯ï¼šæ‰€æœ‰æ•°å­—éƒ½æœ‰æ¥æº
- å¯éªŒè¯ï¼šå¯ä»¥é‡æ–°è®¡ç®—éªŒè¯
- å¯æ‰©å±•ï¼šæ˜“äºæ·»åŠ æ–°å­—æ®µ

### 4. åˆ†ç¦»å…³æ³¨ç‚¹

**æ¨¡å—èŒè´£**:
- `agent_core`: æ„å›¾è§£æ + å·¥å…·è°ƒåº¦
- `conversation`: å†å²ç®¡ç† + ä¸Šä¸‹æ–‡
- `llm_interface`: LLMé€šä¿¡
- `plotting_tools`: å¯è§†åŒ– + ç»Ÿè®¡

**å¥½å¤„**: æ˜“äºæµ‹è¯•ã€ç»´æŠ¤å’Œæ‰©å±•ã€‚

### 5. æ¸è¿›å¼LLMé›†æˆ

**Level 0**: çº¯ç¡®å®šæ€§ï¼ˆæ— LLMï¼‰
```python
agent = StatisticalAgent(enable_llm_fallback_chat=False)
# ä»…æ”¯æŒé¢„å®šä¹‰æŸ¥è¯¢
```

**Level 1**: LLMå¯¹è¯å›é€€
```python
agent = StatisticalAgent(enable_llm_fallback_chat=True)
# æœªè¯†åˆ«æ„å›¾æ—¶ä½¿ç”¨LLMå¯¹è¯ï¼ˆä¸æ¶‰åŠæ•°å€¼ï¼‰
```

**Level 2**: LLMç»“æœè§£é‡Šï¼ˆå®éªŒæ€§ï¼‰
```python
agent = StatisticalAgent(enable_llm_interpretation=True)
# LLMæä¾›ä¸“å®¶çº§è§£é‡Šï¼ˆåŸºäºå·¥å…·è¿”å›çš„ç¡®åˆ‡æ•°å­—ï¼‰
```

---

## ç¤ºä¾‹æŸ¥è¯¢

### ç»Ÿè®¡åˆ†æ

```python
# 1. å…¨é¢ç»Ÿè®¡æ‘˜è¦
agent.chat("show statistics for sensor_2")
agent.chat("summary of sensor_7 and sensor_11")

# 2. ç‰¹å®šæŒ‡æ ‡
agent.chat("mean and variance of sensor_2")
agent.chat("show median and std for sensor_7")

# 3. åˆ†ç»„ç»Ÿè®¡
agent.chat("compare mean of sensor_11 for OK and KO")
```

### å¯è§†åŒ–

```python
# 1. åˆ†å¸ƒå›¾
agent.chat("histogram of sensor_2")
agent.chat("show boxplot for sensor_11")
agent.chat("plot violin for sensor_7")
agent.chat("kde plot for sensor_4")

# 2. æ—¶é—´åºåˆ—
agent.chat("time series of sensor_2")
agent.chat("show time series for KO samples of sensor_7")

# 3. é¢‘è°±åˆ†æ
agent.chat("fft for sensor_4")
agent.chat("plot frequency spectrum of sensor_11")

# 4. å¤šç‰¹å¾å¯¹æ¯”
agent.chat("compare sensor_2, sensor_7, and sensor_11")
```

### ç‰¹å¾é‡è¦æ€§

```python
agent.chat("feature importance")
agent.chat("show top 10 important features")
agent.chat("rank features by importance")
```

### åˆ†ç»„è¿‡æ»¤

```python
agent.chat("histogram of sensor_2 for OK samples")
agent.chat("show time series for KO group of sensor_7")
agent.chat("boxplot for KO samples of sensor_11")
```

---

## å¸¸è§é—®é¢˜

### Q1: Ollamaè¿æ¥å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**é”™è¯¯**: `Cannot connect to Ollama. Please start Ollama service.`

**è§£å†³**:
1. æ£€æŸ¥Ollamaæ˜¯å¦å®‰è£…ï¼š
   ```bash
   ollama --version
   ```

2. å¯åŠ¨OllamaæœåŠ¡ï¼š
   ```bash
   ollama serve
   ```

3. æ‹‰å–æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼š
   ```bash
   ollama pull llama3:latest
   ```

### Q2: å¦‚ä½•æ·»åŠ æ–°çš„å·¥å…·ï¼Ÿ

**æ­¥éª¤**:

1. åœ¨ `agent_core.py` ä¸­æ·»åŠ å·¥å…·æ–¹æ³•ï¼š
```python
def _tool_my_new_analysis(self, param1, param2) -> Dict[str, Any]:
    df = self.current_data
    # æ‰§è¡Œåˆ†æ
    result = ...
    
    return {
        "success": True,
        "message": "âœ… Analysis complete",
        "data": {"result": result}
    }
```

2. æ³¨å†Œå·¥å…·ï¼š
```python
def _register_tool_functions(self):
    return {
        # ... ç°æœ‰å·¥å…· ...
        "my_new_analysis": self._tool_my_new_analysis,
    }
```

3. æ›´æ–°æ„å›¾è§£æï¼š
```python
def _parse_intent(self, user_message):
    text = user_message.lower()
    
    # æ·»åŠ æ–°å…³é”®è¯
    if "my analysis" in text:
        return {
            "type": "tool",
            "tool": "my_new_analysis",
            "args": {"param1": ..., "param2": ...}
        }
    
    # ... ç°æœ‰é€»è¾‘ ...
```

### Q3: å¦‚ä½•è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Ÿ

```python
# æ–¹æ³•1: ä¿®æ”¹ conversation.py çš„ _create_system_prompt()

# æ–¹æ³•2: è¿è¡Œæ—¶æ›´æ–°
agent.conversation.update_system_prompt("""
Your custom system prompt here...
""")

# æ–¹æ³•3: æ·»åŠ ä¸Šä¸‹æ–‡
agent.conversation.add_context("""
Additional context about current data...
""")
```

### Q4: å¦‚ä½•å¯¼å‡ºåˆ†æç»“æœï¼Ÿ

```python
# 1. è·å–å·¥å…·ç»“æœ
response = agent.chat("show statistics for sensor_2")
tool_result = response['tool_results'][0]

# 2. æå–æ•°æ®
data = tool_result.get('data', {})

# 3. è½¬æ¢ä¸ºDataFrame
import pandas as pd
df_result = pd.DataFrame(data)

# 4. ä¿å­˜
df_result.to_csv("analysis_result.csv", index=False)
```

### Q5: å›¾è¡¨ä¸æ˜¾ç¤ºæ€ä¹ˆåŠï¼Ÿ

**Streamlitç¯å¢ƒ**:
```python
response = agent.chat("histogram of sensor_2")
for fig in response['plots']:
    st.pyplot(fig)
```

**Jupyter Notebook**:
```python
import matplotlib.pyplot as plt
response = agent.chat("histogram of sensor_2")
for fig in response['plots']:
    plt.show()
```

**ä¿å­˜åˆ°æ–‡ä»¶**:
```python
response = agent.chat("histogram of sensor_2")
for i, fig in enumerate(response['plots']):
    fig.savefig(f"plot_{i}.png", dpi=300, bbox_inches='tight')
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®é¢„å¤„ç†

```python
# æå‰è½¬æ¢æ•°æ®ç±»å‹
df['sensor_2'] = pd.to_numeric(df['sensor_2'], errors='coerce')

# ç§»é™¤å®Œå…¨ç©ºçš„åˆ—
df = df.dropna(axis=1, how='all')

# è®¾ç½®æ—¶é—´åˆ—ï¼ˆé¿å…é‡å¤æ£€æµ‹ï¼‰
df.attrs['time_column'] = 'time_cycles'
```

### 2. LLMè°ƒç”¨ä¼˜åŒ–

```python
# ç¦ç”¨LLMå›é€€ï¼ˆå¦‚æœåªç”¨é¢„å®šä¹‰æŸ¥è¯¢ï¼‰
agent = StatisticalAgent(
    enable_llm_fallback_chat=False,
    enable_llm_interpretation=False
)

# å‡å°‘å¯¹è¯å†å²é•¿åº¦
agent.conversation.max_history = 10
```

### 3. ç»˜å›¾ä¼˜åŒ–

```python
# å‡å°‘binsæ•°é‡ï¼ˆå¤§æ•°æ®é›†ï¼‰
agent.plotter.plot_distribution_comparison(df, "sensor_2", bins=20)

# å…³é—­ä¸éœ€è¦çš„å›¾å½¢
import matplotlib.pyplot as plt
plt.close('all')  # é‡Šæ”¾å†…å­˜
```

---

## æœªæ¥æ‰©å±•æ–¹å‘

### 1. åŠŸèƒ½æ‰©å±•

- [ ] å¼‚å¸¸æ£€æµ‹å·¥å…·
- [ ] è¶‹åŠ¿åˆ†æï¼ˆçº¿æ€§å›å½’ã€LOESSï¼‰
- [ ] èšç±»åˆ†æï¼ˆK-meansã€DBSCANï¼‰
- [ ] é™ç»´å¯è§†åŒ–ï¼ˆPCAã€t-SNEï¼‰
- [ ] è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ

### 2. æ€§èƒ½ä¼˜åŒ–

- [ ] å¹¶è¡Œè®¡ç®—æ”¯æŒï¼ˆå¤šæ ¸ï¼‰
- [ ] ç¼“å­˜æœºåˆ¶ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- [ ] å¢é‡åˆ†æï¼ˆå¤§æ•°æ®é›†ï¼‰
- [ ] GPUåŠ é€Ÿï¼ˆæ·±åº¦å­¦ä¹ ç‰¹å¾ï¼‰

### 3. ç”¨æˆ·ä½“éªŒ

- [ ] æŸ¥è¯¢å»ºè®®ï¼ˆè‡ªåŠ¨è¡¥å…¨ï¼‰
- [ ] é”™è¯¯æ¢å¤ï¼ˆæ™ºèƒ½é‡è¯•ï¼‰
- [ ] è¿›åº¦æŒ‡ç¤ºï¼ˆé•¿æ—¶é—´è®¡ç®—ï¼‰
- [ ] äº¤äº’å¼å›¾è¡¨ï¼ˆPlotlyï¼‰

### 4. é›†æˆæ‰©å±•

- [ ] æ”¯æŒå…¶ä»–LLMåç«¯ï¼ˆOpenAIã€Claudeï¼‰
- [ ] æ•°æ®åº“è¿æ¥ï¼ˆSQLæŸ¥è¯¢ï¼‰
- [ ] å®æ—¶æ•°æ®æµï¼ˆKafkaã€MQTTï¼‰
- [ ] å¯¼å‡ºæ ¼å¼ï¼ˆPDFã€Excelã€PowerPointï¼‰

---

## è´¡çŒ®æŒ‡å—

### ä»£ç é£æ ¼

- éµå¾ªPEP 8
- ä½¿ç”¨ç±»å‹æ³¨è§£
- æ·»åŠ docstring
- ç¼–å†™å•å…ƒæµ‹è¯•

### æµ‹è¯•

```bash
# è¿è¡Œæµ‹è¯•
pytest tests/

# è¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src/agent tests/
```

### æäº¤è§„èŒƒ

```
feat: æ·»åŠ æ–°åŠŸèƒ½
fix: ä¿®å¤bug
docs: æ–‡æ¡£æ›´æ–°
refactor: ä»£ç é‡æ„
test: æµ‹è¯•ç›¸å…³
```

---

## è®¸å¯è¯

MIT License

---

## è”ç³»æ–¹å¼

- é¡¹ç›®åœ°å€: [GitHub Repository]
- é—®é¢˜åé¦ˆ: [Issues]
- æ–‡æ¡£æ›´æ–°: 2026-01-10

---

**æœ€åæ›´æ–°**: 2026å¹´1æœˆ10æ—¥  
**ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤è€…**: [Your Team]
